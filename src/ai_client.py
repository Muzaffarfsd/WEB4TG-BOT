import asyncio
import logging
import re
from typing import Any, List, Dict, Optional, Tuple
from google import genai
from google.genai import types
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception

from src.config import config
from src.knowledge_base import SYSTEM_PROMPT

logger = logging.getLogger(__name__)


def is_rate_limit_error(exc: BaseException) -> bool:
    exc_str = str(exc).lower()
    exc_type = type(exc).__name__
    if "429" in exc_str or "rate" in exc_str or "quota" in exc_str:
        return True
    if "resourceexhausted" in exc_type.lower():
        return True
    if "too many requests" in exc_str:
        return True
    return False

VALID_TEMPLATE_PRICES = {150000, 170000, 180000, 200000}
VALID_SUBSCRIPTION_PRICES = {9900, 14900, 24900}
VALID_FEATURE_PRICE_MIN = 12000
VALID_FEATURE_PRICE_MAX = 120000
VALID_PREPAYMENT_PERCENT = 35
VALID_FREE_FIXES_DAYS = 14
VALID_TIMELINE_MIN = 7
VALID_TIMELINE_MAX = 30

KNOWN_FEATURES = {
    "–∫–∞—Ç–∞–ª–æ–≥", "–∫–æ—Ä–∑–∏–Ω–∞", "–∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è", "–ø–æ–∏—Å–∫", "–∏–∑–±—Ä–∞–Ω–Ω–æ–µ", "–æ—Ç–∑—ã–≤—ã",
    "–æ–ø–ª–∞—Ç–∞", "–ø–æ–¥–ø–∏—Å–∫–∏", "—Ä–∞—Å—Å—Ä–æ—á–∫–∞", "–¥–æ—Å—Ç–∞–≤–∫–∞", "–ø–≤–∑", "—ç–∫—Å–ø—Ä–µ—Å—Å",
    "push", "—á–∞—Ç", "–≤–∏–¥–µ–æ–∑–≤–æ–Ω–∫–∏", "–ª–æ—è–ª—å–Ω–æ—Å—Ç—å", "–ø—Ä–æ–º–æ–∫–æ–¥—ã", "—Ä–µ—Ñ–µ—Ä–∞–ª—å–Ω–∞—è",
    "–∞–Ω–∞–ª–∏—Ç–∏–∫–∞", "–∞–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å", "crm", "—Ç—Ä–µ–∫–∏–Ω–≥", "–±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ", "–æ—á–µ—Ä–µ–¥—å",
    "–∫–∞–ª–µ–Ω–¥–∞—Ä—å", "ai", "—á–∞—Ç-–±–æ—Ç", "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏", "–∞–≤—Ç–æ-–æ—Ç–≤–µ—Ç—ã", "—É–º–Ω—ã–π –ø–æ–∏—Å–∫",
    "–≥–æ–ª–æ—Å–æ–≤–æ–π", "telegram –±–æ—Ç", "whatsapp", "google maps", "sms", "email", "1c", "api",
}

PRICE_CORRECTION_MAP = {
    "–º–∞–≥–∞–∑–∏–Ω": 150000, "–∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω": 150000,
    "—Ä–µ—Å—Ç–æ—Ä–∞–Ω": 180000, "–¥–æ—Å—Ç–∞–≤–∫–∞": 180000,
    "—Ñ–∏—Ç–Ω–µ—Å": 200000, "—Ñ–∏—Ç–Ω–µ—Å-–∫–ª—É–±": 200000,
    "—É—Å–ª—É–≥–∏": 170000, "—Å–µ—Ä–≤–∏—Å": 170000,
}


def validate_response(response_text: str) -> Tuple[bool, str]:
    is_valid = True
    cleaned = response_text

    price_pattern = re.compile(r'(\d[\d\s]*\d)\s*(?:‚ÇΩ|—Ä—É–±|—Ä—É–±–ª–µ–π)')
    for match in price_pattern.finditer(cleaned):
        raw_price = match.group(1).replace(" ", "").replace("\u00a0", "")
        try:
            price_val = int(raw_price)
        except ValueError:
            continue

        if price_val < 1000:
            continue

        if price_val in VALID_TEMPLATE_PRICES:
            continue
        if price_val in VALID_SUBSCRIPTION_PRICES:
            continue
        if VALID_FEATURE_PRICE_MIN <= price_val <= VALID_FEATURE_PRICE_MAX:
            if price_val % 1000 == 0:
                continue

        is_combined = False
        if price_val % 1000 == 0:
            for tp in VALID_TEMPLATE_PRICES:
                remainder = price_val - tp
                if remainder > 0 and remainder % 1000 == 0 and remainder <= 400000:
                    is_combined = True
                    break
        if is_combined:
            continue

        if 100000 <= price_val <= 500000:
            is_valid = False
            closest = min(VALID_TEMPLATE_PRICES, key=lambda p: abs(p - price_val))
            old_price_str = match.group(0)
            new_price_str = f"{closest:,}".replace(",", " ") + " ‚ÇΩ"
            cleaned = cleaned.replace(old_price_str, new_price_str)
            logger.warning(f"Replaced suspicious price {price_val} with {closest}")

    prepay_pattern = re.compile(r'(\d+)\s*%\s*(?:–ø—Ä–µ–¥–æ–ø–ª–∞—Ç|–∞–≤–∞–Ω—Å)')
    for match in prepay_pattern.finditer(cleaned.lower()):
        pct = int(match.group(1))
        if pct != VALID_PREPAYMENT_PERCENT:
            is_valid = False
            cleaned = cleaned.replace(match.group(0), f"{VALID_PREPAYMENT_PERCENT}% –ø—Ä–µ–¥–æ–ø–ª–∞—Ç")
            logger.warning(f"Corrected prepayment from {pct}% to {VALID_PREPAYMENT_PERCENT}%")

    fixes_pattern = re.compile(r'(\d+)\s*(?:–¥–Ω|–¥–µ–Ω—å|–¥–Ω–µ–π)\s*(?:–±–µ—Å–ø–ª–∞—Ç–Ω|–ø—Ä–∞–≤–æ–∫|–∏—Å–ø—Ä–∞–≤–ª–µ–Ω)')
    for match in fixes_pattern.finditer(cleaned.lower()):
        days = int(match.group(1))
        if days != VALID_FREE_FIXES_DAYS:
            is_valid = False
            old_text = match.group(0)
            new_text = old_text.replace(str(days), str(VALID_FREE_FIXES_DAYS))
            cleaned = cleaned.replace(match.group(0), new_text)
            logger.warning(f"Corrected free fixes from {days} to {VALID_FREE_FIXES_DAYS} days")

    timeline_pattern = re.compile(r'–∑–∞\s*(\d+)\s*(?:–¥–Ω|–¥–µ–Ω—å|–¥–Ω–µ–π)')
    for match in timeline_pattern.finditer(cleaned.lower()):
        days = int(match.group(1))
        if days < VALID_TIMELINE_MIN or days > VALID_TIMELINE_MAX:
            is_valid = False
            corrected = max(VALID_TIMELINE_MIN, min(days, VALID_TIMELINE_MAX))
            old_text = match.group(0)
            new_text = old_text.replace(str(days), str(corrected))
            cleaned = cleaned.replace(old_text, new_text)
            logger.warning(f"Corrected timeline from {days} to {corrected} days")

    guarantee_patterns = [
        r'–≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º\s+(?:100|–ø–æ–ª–Ω)',
        r'–≥–∞—Ä–∞–Ω—Ç–∏—è\s+(?:–≤–æ–∑–≤—Ä–∞—Ç–∞|–¥–µ–Ω–µ–≥)',
        r'100%\s*(?:–≥–∞—Ä–∞–Ω—Ç–∏—è|uptime|–∞–ø—Ç–∞–π–º)',
        r'–±–µ—Å–ø–ª–∞—Ç–Ω(?:–æ|—ã–π|–∞—è|—ã–µ)\s+(?:–¥–æ—Ä–∞–±–æ—Ç–∫|–º–æ–¥—É–ª|—Ñ—É–Ω–∫—Ü–∏)',
    ]
    for pat in guarantee_patterns:
        if re.search(pat, cleaned.lower()):
            is_valid = False
            logger.warning(f"Unauthorized guarantee detected: {pat}")

    discount_patterns = [
        r'—Å–∫–∏–¥–∫[–∞–µ—É]\s+\d+\s*%(?!\s*(?:–∑–∞\s+–º–æ–Ω–µ—Ç|–ø—Ä–∏\s+–Ω–∞–∫–æ–ø–ª–µ–Ω|–∑–∞\s+coin))',
        r'(?:–¥–∞—Ä–∏–º|–¥–∞—ë–º|–ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ–º)\s+—Å–∫–∏–¥–∫',
        r'–ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω\w*\s+—Å–∫–∏–¥–∫',
        r'—Å–ø–µ—Ü–∏–∞–ª—å–Ω\w*\s+—Å–∫–∏–¥–∫',
    ]
    for pat in discount_patterns:
        if re.search(pat, cleaned.lower()):
            context_around = cleaned.lower()
            if "–º–æ–Ω–µ—Ç" not in context_around and "coin" not in context_around and "bonus" not in context_around:
                is_valid = False
                logger.warning(f"Unauthorized discount detected: {pat}")

    ALLOWED_DOMAINS = {
        "web4tg.com", "t.me", "youtube.com", "www.youtube.com",
        "instagram.com", "www.instagram.com", "tiktok.com", "www.tiktok.com",
        "telegram.me",
    }
    url_pattern = re.compile(r'(?:\[([^\]]*)\]\()?(?:https?://)([\w.-]+)(/[^\s\)\]]*)?(?:\))?')
    for match in url_pattern.finditer(cleaned):
        domain = match.group(2).lower()
        if domain not in ALLOWED_DOMAINS:
            is_valid = False
            full_match = match.group(0)
            logger.warning(f"Removed hallucinated URL with domain '{domain}': {full_match}")
            cleaned = cleaned.replace(full_match, "")

    cleaned = re.sub(r'\[–°–∫–∞—á–∞—Ç—å[^\]]*\]\s*', '', cleaned)
    cleaned = re.sub(r'üìÑ\s*\*?\*?\s*$', '', cleaned, flags=re.MULTILINE)
    cleaned = re.sub(r'\n{3,}', '\n\n', cleaned)

    return (is_valid, cleaned)


def _compute_adaptive_word_limit(user_message: str, query_context: str = "") -> int:
    user_words = len(user_message.split())
    user_chars = len(user_message)

    if user_words <= 3 or user_chars <= 15:
        return 50
    if user_words <= 8 or user_chars <= 40:
        return 80
    if query_context in ("faq", "greeting", "simple"):
        return 80
    if query_context in ("creative", "upsell"):
        return 180
    if query_context in ("objection", "complex", "sales", "closing", "decision"):
        return 180

    question_marks = user_message.count("?")
    if question_marks >= 2 or user_words > 30:
        return 180

    return 120


def check_response_quality(response_text: str, user_message: str, query_context: str = "") -> str:
    if not response_text or not response_text.strip():
        return response_text

    cleaned = response_text.strip()

    fluff_openers = [
        "–ö–æ–Ω–µ—á–Ω–æ!", "–ö–æ–Ω–µ—á–Ω–æ,", "–ë–µ–∑—É—Å–ª–æ–≤–Ω–æ!", "–ë–µ–∑—É—Å–ª–æ–≤–Ω–æ,",
        "–†–∞–∑—É–º–µ–µ—Ç—Å—è!", "–†–∞–∑—É–º–µ–µ—Ç—Å—è,", "–ù–µ—Å–æ–º–Ω–µ–Ω–Ω–æ!", "–ù–µ—Å–æ–º–Ω–µ–Ω–Ω–æ,",
        "–° —É–¥–æ–≤–æ–ª—å—Å—Ç–≤–∏–µ–º!", "–° —É–¥–æ–≤–æ–ª—å—Å—Ç–≤–∏–µ–º,",
        "–û—Ç–ª–∏—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å!", "–û—Ç–ª–∏—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å,",
        "–•–æ—Ä–æ—à–∏–π –≤–æ–ø—Ä–æ—Å!", "–•–æ—Ä–æ—à–∏–π –≤–æ–ø—Ä–æ—Å,",
        "–°–ø–∞—Å–∏–±–æ –∑–∞ –≤–æ–ø—Ä–æ—Å!", "–°–ø–∞—Å–∏–±–æ –∑–∞ –≤–æ–ø—Ä–æ—Å,",
        "–†–∞–¥, —á—Ç–æ –≤—ã —Å–ø—Ä–æ—Å–∏–ª–∏!", "–†–∞–¥, —á—Ç–æ —Å–ø—Ä–æ—Å–∏–ª–∏!",
        "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ!", "–î–æ–±—Ä—ã–π –¥–µ–Ω—å!",
        "–ë–ª–∞–≥–æ–¥–∞—Ä—é –∑–∞ –æ–±—Ä–∞—â–µ–Ω–∏–µ!", "–ë–ª–∞–≥–æ–¥–∞—Ä—é!",
    ]
    for opener in fluff_openers:
        if cleaned.startswith(opener):
            rest = cleaned[len(opener):].strip()
            if rest:
                cleaned = rest
                logger.debug(f"Removed fluff opener: '{opener}'")
            break

    bot_phrases = [
        "–ß–µ–º —è –º–æ–≥—É –≤–∞–º –ø–æ–º–æ—á—å?", "–ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?",
        "–û–±—Ä–∞—â–∞–π—Ç–µ—Å—å, –µ—Å–ª–∏ –±—É–¥—É—Ç –≤–æ–ø—Ä–æ—Å—ã!",
        "–Ø –≤—Å–µ–≥–¥–∞ –≥–æ—Ç–æ–≤ –ø–æ–º–æ—á—å!", "–í—Å–µ–≥–¥–∞ —Ä–∞–¥ –ø–æ–º–æ—á—å!",
        "–ù–µ —Å—Ç–µ—Å–Ω—è–π—Ç–µ—Å—å –æ–±—Ä–∞—â–∞—Ç—å—Å—è!",
        "–ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –µ—â—ë –≤–æ–ø—Ä–æ—Å—ã, –Ω–µ —Å—Ç–µ—Å–Ω—è–π—Ç–µ—Å—å –∑–∞–¥–∞–≤–∞—Ç—å!",
    ]
    for phrase in bot_phrases:
        if cleaned.endswith(phrase):
            rest = cleaned[:-len(phrase)].strip()
            if rest:
                cleaned = rest
                logger.debug(f"Removed bot phrase: '{phrase}'")

    response_words = len(cleaned.split())

    max_words = _compute_adaptive_word_limit(user_message, query_context)
    if response_words > max_words:
        sentences = re.split(r'(?<=[.!?])\s+', cleaned)
        trimmed = []
        word_count = 0
        for sent in sentences:
            sent_words = len(sent.split())
            if word_count + sent_words > max_words and trimmed:
                break
            trimmed.append(sent)
            word_count += sent_words
        if trimmed:
            cleaned = " ".join(trimmed)
            logger.debug(f"Adaptive trim: {response_words} ‚Üí {word_count} words (limit={max_words})")

    if len(cleaned.split()) > 40:
        cta_patterns = [
            r'–¥–∞–≤–∞–π—Ç–µ', r'–Ω–∞–ø–∏—à–∏—Ç–µ', r'–ø–æ–ø—Ä–æ–±—É–π—Ç–µ', r'–ø–æ—Å–º–æ—Ç—Ä–∏—Ç–µ',
            r'—Ä–∞—Å—Å–∫–∞–∂–∏—Ç–µ', r'–≤—ã–±–∏—Ä–∞–π—Ç–µ', r'–∑–∞–∫–∞–∂–∏—Ç–µ', r'–∑–∞–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å',
            r'—Å–≤—è–∂–∏—Ç–µ—Å—å', r'–æ–±—Ä–∞—â–∞–π—Ç–µ—Å—å', r'–∑–≤–æ–Ω–∏—Ç–µ', r'–ø–∏—à–∏—Ç–µ',
            r'/\w+', r'—Ö–æ—Ç–∏—Ç–µ\s', r'–≥–æ—Ç–æ–≤—ã\s', r'–Ω–∞—á–Ω—ë–º',
            r'\?$', r'–º–æ–≥—É\s', r'–ø—Ä–µ–¥–ª–∞–≥–∞—é', r'–Ω–∞—á–∞—Ç—å',
            r'—É–¥–æ–±–Ω–æ\s', r'–∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ\?',
        ]
        has_cta = any(re.search(pat, cleaned.lower()) for pat in cta_patterns)
        if not has_cta:
            if "?" not in cleaned[-100:]:
                cleaned += "\n\n–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω–µ–µ –æ –≤–∞—à–µ–º –ø—Ä–æ–µ–∫—Ç–µ ‚Äî –ø–æ–¥–±–µ—Ä—É –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ)"
                logger.debug("Added CTA to response without call-to-action")

    return cleaned


class AIClient:
    def __init__(self):
        from src.config import get_gemini_client
        self._client = get_gemini_client()

    def select_model_and_config(self, query_context: Optional[str] = None, dynamic_system_prompt: Optional[str] = None) -> Tuple[str, types.GenerateContentConfig]:
        sys_prompt = dynamic_system_prompt or SYSTEM_PROMPT

        if not query_context:
            return config.fast_model_name, types.GenerateContentConfig(
                system_instruction=sys_prompt,
                max_output_tokens=config.max_tokens,
                temperature=config.temperature
            )

        ctx = query_context.lower()

        if ctx in ("faq", "greeting", "simple"):
            return config.fast_model_name, types.GenerateContentConfig(
                system_instruction=sys_prompt,
                max_output_tokens=1000,
                temperature=config.temperature_precise
            )
        elif ctx in ("objection", "complex", "sales"):
            return config.thinking_model_name, types.GenerateContentConfig(
                system_instruction=sys_prompt,
                max_output_tokens=config.max_tokens,
                temperature=config.temperature,
                thinking_config=types.ThinkingConfig(thinking_budget=2048)
            )
        elif ctx in ("closing", "decision"):
            return config.thinking_model_name, types.GenerateContentConfig(
                system_instruction=sys_prompt,
                max_output_tokens=config.max_tokens,
                temperature=config.temperature,
                thinking_config=types.ThinkingConfig(thinking_budget=2048)
            )
        elif ctx in ("creative", "upsell"):
            return config.fast_model_name, types.GenerateContentConfig(
                system_instruction=sys_prompt,
                max_output_tokens=config.max_tokens,
                temperature=config.temperature_creative
            )
        else:
            return config.fast_model_name, types.GenerateContentConfig(
                system_instruction=sys_prompt,
                max_output_tokens=config.max_tokens,
                temperature=config.temperature
            )

    def _get_contextual_fallback(self, user_message: str) -> str:
        msg = user_message.lower() if user_message else ""

        if any(w in msg for w in ["—Ü–µ–Ω", "—Å—Ç–æ–∏–º–æ—Å—Ç—å", "—Å–∫–æ–ª—å–∫–æ —Å—Ç–æ–∏—Ç", "–ø—Ä–∞–π—Å", "–±—é–¥–∂–µ—Ç", "–¥–æ—Ä–æ–≥–æ", "price"]):
            return (
                "–®–∞–±–ª–æ–Ω—ã Mini App –æ—Ç 150 000 ‚ÇΩ (–º–∞–≥–∞–∑–∏–Ω) –¥–æ 200 000 ‚ÇΩ (—Ñ–∏—Ç–Ω–µ—Å-–∫–ª—É–±). "
                "–î–æ–ø. —Ñ—É–Ω–∫—Ü–∏–∏ –æ—Ç 12 000 ‚ÇΩ. –ü—Ä–µ–¥–æ–ø–ª–∞—Ç–∞ 35%, 14 –¥–Ω–µ–π –ø—Ä–∞–≤–æ–∫ –±–µ—Å–ø–ª–∞—Ç–Ω–æ. "
                "–ù–∞–ø–∏—à–∏—Ç–µ /price –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –ø—Ä–∞–π—Å–∞ –∏–ª–∏ —Ä–∞—Å—Å–∫–∞–∂–∏—Ç–µ –æ –ø—Ä–æ–µ–∫—Ç–µ ‚Äî –ø–æ—Å—á–∏—Ç–∞—é —Ç–æ—á–Ω–µ–µ)"
            )
        elif any(w in msg for w in ["–ø–æ—Ä—Ç—Ñ–æ–ª–∏–æ", "–ø—Ä–∏–º–µ—Ä—ã", "–∫–µ–π—Å", "—Ä–∞–±–æ—Ç", "portfolio"]):
            return (
                "–£ –Ω–∞—Å –µ—Å—Ç—å –∫–µ–π—Å—ã –≤ e-commerce, —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞—Ö, —Ñ–∏—Ç–Ω–µ—Å–µ, —É—Å–ª—É–≥–∞—Ö –∏ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏. "
                "–ù–∞–ø–∏—à–∏—Ç–µ /portfolio —á—Ç–æ–±—ã –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ø—Ä–∏–º–µ—Ä—ã —Ä–∞–±–æ—Ç)"
            )
        elif any(w in msg for w in ["—Å—Ä–æ–∫", "–∫–æ–≥–¥–∞", "–±—ã—Å—Ç—Ä–æ", "—Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π", "–≤—Ä–µ–º—è", "deadline"]):
            return (
                "–°—Ä–æ–∫–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏: –ø—Ä–æ—Å—Ç–æ–π –ø—Ä–æ–µ–∫—Ç 7-10 –¥–Ω–µ–π, —Å—Ä–µ–¥–Ω–∏–π 10-15, —Å–ª–æ–∂–Ω—ã–π 15-20 –¥–Ω–µ–π. "
                "–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –æ –ø—Ä–æ–µ–∫—Ç–µ ‚Äî –Ω–∞–∑–æ–≤—É —Ç–æ—á–Ω—ã–µ —Å—Ä–æ–∫–∏)"
            )
        elif any(w in msg for w in ["–æ–ø–ª–∞—Ç", "–∑–∞–ø–ª–∞—Ç–∏—Ç—å", "—Ä–µ–∫–≤–∏–∑–∏—Ç", "—Å—á—ë—Ç", "payment"]):
            return (
                "–û–ø–ª–∞—Ç–∞ –≤ 2 —ç—Ç–∞–ø–∞: 35% –ø—Ä–µ–¥–æ–ø–ª–∞—Ç–∞ –¥–æ –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç, 65% –ø–æ—Å–ª–µ —Å–¥–∞—á–∏. "
                "–ù–∞–ø–∏—à–∏—Ç–µ /payment –¥–ª—è —Ä–µ–∫–≤–∏–∑–∏—Ç–æ–≤)"
            )
        elif any(w in msg for w in ["–ø–æ–¥–ø–∏—Å–∫", "–æ–±—Å–ª—É–∂–∏–≤", "–ø–æ–¥–¥–µ—Ä–∂–∫", "subscription"]):
            return (
                "–ü–æ–¥–ø–∏—Å–∫–∏ –Ω–∞ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ: –ú–∏–Ω–∏ 9 900‚ÇΩ/–º–µ—Å, –°—Ç–∞–Ω–¥–∞—Ä—Ç 14 900‚ÇΩ/–º–µ—Å, –ü—Ä–µ–º–∏—É–º 24 900‚ÇΩ/–º–µ—Å. "
                "–ù–∞–ø–∏—à–∏—Ç–µ /price ‚Üí –ü–æ–¥–ø–∏—Å–∫–∏ –¥–ª—è –¥–µ—Ç–∞–ª–µ–π)"
            )
        elif any(w in msg for w in ["—Å–∫–∏–¥–∫", "–∞–∫—Ü–∏", "–ø—Ä–æ–º–æ–∫–æ–¥", "discount", "–º–æ–Ω–µ—Ç", "bonus"]):
            return (
                "–°–∫–∏–¥–∫–∏ –∑–∞ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ –º–æ–Ω–µ—Ç—ã: –æ—Ç 5% (500 –º–æ–Ω–µ—Ç) –¥–æ 25% (2500+ –º–æ–Ω–µ—Ç). "
                "–ó–∞—Ä–∞–±–∞—Ç—ã–≤–∞–π—Ç–µ —á–µ—Ä–µ–∑ /referral –∏ –∑–∞–¥–∞–Ω–∏—è –≤ /bonus)"
            )
        elif any(w in msg for w in ["–ø—Ä–∏–≤–µ—Ç", "–∑–¥—Ä–∞–≤—Å—Ç–≤", "–¥–æ–±—Ä—ã–π", "hello", "hi"]):
            return (
                "–ü—Ä–∏–≤–µ—Ç) –Ø –ê–ª–µ–∫—Å –∏–∑ WEB4TG Studio ‚Äî –¥–µ–ª–∞–µ–º Telegram Mini Apps –¥–ª—è –±–∏–∑–Ω–µ—Å–∞. "
                "–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –æ –≤–∞—à–µ–º –ø—Ä–æ–µ–∫—Ç–µ –∏–ª–∏ –∑–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å ‚Äî –ø–æ–º–æ–≥—É —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è)"
            )
        elif any(w in msg for w in ["–∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü", "—Å–æ–∑–≤–æ–Ω", "–∑–≤–æ–Ω–æ–∫", "–≤—Å—Ç—Ä–µ—á"]):
            return (
                "–ë–µ—Å–ø–ª–∞—Ç–Ω–∞—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è ‚Äî –æ—Ç–ª–∏—á–Ω–∞—è –∏–¥–µ—è) "
                "–ù–∞–ø–∏—à–∏—Ç–µ /consult —á—Ç–æ–±—ã –≤—ã–±—Ä–∞—Ç—å —É–¥–æ–±–Ω–æ–µ –≤—Ä–µ–º—è –¥–ª—è —Å–æ–∑–≤–æ–Ω–∞)"
            )
        else:
            return (
                "–°–µ–π—á–∞—Å –Ω–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ —Å –æ—Ç–≤–µ—Ç–æ–º. "
                "–ù–∞–ø–∏—à–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å –µ—â—ë —Ä–∞–∑ —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É, –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /help –¥–ª—è –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ –ø–æ –∫–æ–º–∞–Ω–¥–∞–º)"
            )

    async def generate_response_stream(
        self,
        messages: List[Dict],
        thinking_level: str = "medium",
        on_chunk=None,
        max_retries: int = 2,
        query_context: Optional[str] = None,
        dynamic_system_prompt: Optional[str] = None
    ) -> str:
        if query_context:
            model, gen_config = self.select_model_and_config(query_context, dynamic_system_prompt)
        elif thinking_level == "high":
            model = config.thinking_model_name
            gen_config = types.GenerateContentConfig(
                system_instruction=dynamic_system_prompt or SYSTEM_PROMPT,
                max_output_tokens=config.max_tokens,
                temperature=config.temperature,
                thinking_config=types.ThinkingConfig(thinking_budget=2048)
            )
        else:
            model = config.fast_model_name
            gen_config = types.GenerateContentConfig(
                system_instruction=dynamic_system_prompt or SYSTEM_PROMPT,
                max_output_tokens=config.max_tokens,
                temperature=config.temperature
            )

        user_message = ""
        for msg in reversed(messages):
            if msg.get("role") == "user":
                parts = msg.get("parts", [])
                if parts and isinstance(parts[0], dict):
                    user_message = parts[0].get("text", "")
                elif parts and isinstance(parts[0], str):
                    user_message = parts[0]
                break

        for attempt in range(max_retries + 1):
            try:
                import queue
                chunk_queue = queue.Queue()
                stream_error: list[Optional[Exception]] = [None]

                def _stream_in_thread():
                    full = ""
                    try:
                        stream = self._client.models.generate_content_stream(
                            model=model,
                            contents=messages,  # type: ignore[arg-type]
                            config=gen_config
                        )
                        for chunk in stream:
                            if chunk.text:
                                full += chunk.text
                                chunk_queue.put(full)
                    except Exception as e:
                        stream_error[0] = e
                        logger.warning(f"Stream error (attempt {attempt+1}/{max_retries+1}): {type(e).__name__}: {e}")
                    finally:
                        chunk_queue.put(None)
                    return full

                stream_task = asyncio.get_event_loop().run_in_executor(None, _stream_in_thread)

                full_text = ""
                while True:
                    try:
                        partial = await asyncio.to_thread(chunk_queue.get, timeout=0.3)
                        if partial is None:
                            break
                        full_text = partial
                        if on_chunk:
                            try:
                                await on_chunk(full_text)
                            except Exception:
                                pass
                    except Exception:
                        if stream_task.done():
                            while not chunk_queue.empty():
                                item = chunk_queue.get_nowait()
                                if item is None:
                                    break
                                full_text = item
                                if on_chunk:
                                    try:
                                        await on_chunk(full_text)
                                    except Exception:
                                        pass
                            break

                result = await stream_task
                if result:
                    full_text = result

                if stream_error[0] and not full_text:
                    if model != config.fast_model_name and attempt == max_retries:
                        logger.warning(f"Pro model failed after {max_retries+1} attempts, cascading to Flash: {stream_error[0]}")
                        model = config.fast_model_name
                        if gen_config.thinking_config:
                            gen_config = types.GenerateContentConfig(
                                system_instruction=gen_config.system_instruction,
                                max_output_tokens=gen_config.max_output_tokens,
                                temperature=gen_config.temperature,
                            )
                        attempt = -1
                        max_retries = 1
                        continue
                    if is_rate_limit_error(stream_error[0]) and attempt < max_retries:
                        delay = 0.5 * (2 ** attempt)
                        logger.info(f"Stream rate limited, retrying in {delay}s (attempt {attempt+1}/{max_retries+1})")
                        await asyncio.sleep(delay)
                        continue
                    elif "timeout" in str(stream_error[0]).lower() and attempt < max_retries:
                        delay = 0.5 * (2 ** attempt)
                        logger.info(f"Stream timeout, auto-retrying in {delay}s (attempt {attempt+1}/{max_retries+1})")
                        await asyncio.sleep(delay)
                        continue
                    elif attempt < max_retries:
                        delay = 0.5 * (2 ** attempt)
                        logger.info(f"Stream failed, retrying in {delay}s (attempt {attempt+1}/{max_retries+1})")
                        await asyncio.sleep(delay)
                        continue

                if full_text:
                    is_valid, cleaned = validate_response(full_text)
                    if not is_valid:
                        logger.warning("Response validation found issues, using cleaned version")
                    return check_response_quality(cleaned, user_message, query_context=query_context or "")

            except Exception as e:
                error_type = type(e).__name__
                error_msg = str(e)
                if is_rate_limit_error(e):
                    if attempt < max_retries:
                        delay = 0.5 * (2 ** attempt)
                        logger.warning(f"Gemini stream rate limit (attempt {attempt+1}), retrying in {delay}s")
                        await asyncio.sleep(delay)
                        continue
                    logger.warning(f"Gemini stream rate limit exhausted: {error_type}: {error_msg}")
                    return self._get_contextual_fallback(user_message)
                if "timeout" in error_msg.lower():
                    if attempt < max_retries:
                        delay = 0.5 * (2 ** attempt)
                        logger.warning(f"Gemini stream timeout (attempt {attempt+1}), auto-retrying in {delay}s")
                        await asyncio.sleep(delay)
                        continue
                    logger.warning(f"Gemini stream timeout exhausted: {error_type}: {error_msg}")
                    return self._get_contextual_fallback(user_message)
                logger.error(f"Gemini stream failed: {error_type}: {error_msg}")
                return self._get_contextual_fallback(user_message)

        logger.warning("Stream retries exhausted, providing contextual fallback")
        return self._get_contextual_fallback(user_message)

    async def generate_response(
        self,
        messages: List[Dict],
        thinking_level: str = "medium",
        max_retries: int = 2,
        retry_delay: float = 0.5,
        query_context: Optional[str] = None,
        dynamic_system_prompt: Optional[str] = None
    ) -> str:
        if query_context:
            model, gen_config = self.select_model_and_config(query_context, dynamic_system_prompt)
        elif thinking_level == "high":
            model = config.thinking_model_name
            gen_config = types.GenerateContentConfig(
                system_instruction=dynamic_system_prompt or SYSTEM_PROMPT,
                max_output_tokens=config.max_tokens,
                temperature=config.temperature,
                thinking_config=types.ThinkingConfig(thinking_budget=2048)
            )
        else:
            model = config.fast_model_name
            gen_config = types.GenerateContentConfig(
                system_instruction=dynamic_system_prompt or SYSTEM_PROMPT,
                max_output_tokens=config.max_tokens,
                temperature=config.temperature
            )

        user_message = ""
        for msg in reversed(messages):
            if msg.get("role") == "user":
                parts = msg.get("parts", [])
                if parts and isinstance(parts[0], dict):
                    user_message = parts[0].get("text", "")
                elif parts and isinstance(parts[0], str):
                    user_message = parts[0]
                break
        
        current_model = model
        current_config = gen_config

        @retry(
            stop=stop_after_attempt(max_retries),
            wait=wait_exponential(multiplier=retry_delay, min=0.5, max=10),
            retry=retry_if_exception(is_rate_limit_error),
            reraise=True
        )
        async def _generate():
            response = await asyncio.to_thread(
                self._client.models.generate_content,
                model=current_model,
                contents=messages,  # type: ignore[arg-type]
                config=current_config
            )
            return response
        
        try:
            response = await _generate()
            
            if response.text:
                is_valid, cleaned = validate_response(response.text)
                if not is_valid:
                    logger.warning("Response validation found issues, using cleaned version")
                return check_response_quality(cleaned, user_message, query_context=query_context or "")
            else:
                logger.warning("Empty response from Gemini")
                return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å."
                
        except Exception as e:
            error_type = type(e).__name__
            error_msg = str(e)
            
            if current_model != config.fast_model_name:
                logger.warning(f"Pro model failed ({error_type}), cascading to Flash")
                current_model = config.fast_model_name
                current_config = types.GenerateContentConfig(
                    system_instruction=current_config.system_instruction,
                    max_output_tokens=current_config.max_output_tokens,
                    temperature=current_config.temperature,
                )
                try:
                    response = await _generate()
                    if response.text:
                        is_valid, cleaned = validate_response(response.text)
                        return check_response_quality(cleaned, user_message, query_context=query_context or "")
                except Exception as fallback_e:
                    logger.error(f"Flash fallback also failed: {fallback_e}")

            if is_rate_limit_error(e):
                logger.warning(f"Gemini rate limit hit: {error_type}: {error_msg}")
            elif "timeout" in error_msg.lower() or "connect" in error_msg.lower():
                logger.error(f"Gemini connection error: {error_type}: {error_msg}")
            else:
                logger.error(f"Gemini request failed: {error_type}: {error_msg}")
            return self._get_contextual_fallback(user_message)
    
    async def generate_response_with_tools(
        self,
        messages: List[Dict],
        thinking_level: str = "medium",
        on_chunk=None,
        query_context: Optional[str] = None,
        dynamic_system_prompt: Optional[str] = None
    ) -> dict:
        """Returns {"text": str, "tool_calls": list[dict], "all_tool_calls": list}"""
        try:
            sys_prompt = dynamic_system_prompt or SYSTEM_PROMPT
            if query_context and query_context in ("objection", "complex", "sales", "closing", "decision"):
                model = config.thinking_model_name
            elif thinking_level == "high":
                model = config.thinking_model_name
            else:
                model = config.fast_model_name

            tools = types.Tool(function_declarations=TOOL_DECLARATIONS)  # type: ignore[arg-type]
            gen_config = types.GenerateContentConfig(
                system_instruction=sys_prompt,
                max_output_tokens=config.max_tokens,
                temperature=config.temperature,
                tools=[tools],
                tool_config=types.ToolConfig(
                    function_calling_config=types.FunctionCallingConfig(mode=types.FunctionCallingConfigMode.AUTO)
                )
            )

            response = await asyncio.to_thread(
                self._client.models.generate_content,
                model=model,
                contents=messages,  # type: ignore[arg-type]
                config=gen_config
            )

            tool_calls = []
            if response.candidates and response.candidates[0].content and response.candidates[0].content.parts:
                for part in response.candidates[0].content.parts:
                    if part.function_call:
                        fc = part.function_call
                        tool_calls.append({
                            "name": fc.name,
                            "args": dict(fc.args) if fc.args else {}
                        })

            if tool_calls:
                return {"text": None, "tool_calls": tool_calls, "all_tool_calls": tool_calls}

            text = response.text if response.text else None
            return {"text": text, "tool_calls": [], "all_tool_calls": []}

        except Exception as e:
            logger.warning(f"Tool calling failed, falling back to regular response: {e}")
            fallback = await self.generate_response(messages, thinking_level)
            return {"text": fallback, "tool_calls": [], "all_tool_calls": []}

    async def agentic_loop(
        self,
        messages: List[Dict],
        tool_executor,
        thinking_level: str = "medium",
        max_steps: int = 4,
        query_context: Optional[str] = None,
        dynamic_system_prompt: Optional[str] = None
    ) -> dict:
        """Multi-step agentic loop: AI calls tools, gets results, decides next action.
        
        Returns {"text": str, "special_actions": list, "all_tool_results": list}
        """
        all_tool_results = []
        special_actions = []
        current_messages = list(messages)
        
        effective_thinking = thinking_level
        if query_context in ("objection", "complex", "sales"):
            effective_thinking = "high"
        elif query_context in ("faq", "greeting", "simple"):
            effective_thinking = "low"

        for step in range(max_steps):
            result = await self.generate_response_with_tools(
                messages=current_messages,
                thinking_level=effective_thinking,
                query_context=query_context,
                dynamic_system_prompt=dynamic_system_prompt
            )
            
            if not result["tool_calls"]:
                return {
                    "text": result["text"],
                    "special_actions": special_actions,
                    "all_tool_results": all_tool_results
                }
            
            step_tool_results = []
            for tc in result["tool_calls"]:
                try:
                    tool_result = await tool_executor(tc["name"], tc["args"])
                except Exception as e:
                    tool_result = f"–û—à–∏–±–∫–∞ –≤—ã–∑–æ–≤–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ {tc['name']}: {e}"
                    logger.error(f"Tool executor error for {tc['name']}: {e}")
                
                if not isinstance(tool_result, str):
                    tool_result = str(tool_result) if tool_result is not None else "–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"
                
                if tool_result.startswith("[PORTFOLIO:"):
                    special_actions.append(("portfolio", tool_result))
                    step_tool_results.append(f"{tc['name']}: –ø–æ–∫–∞–∑–∞–Ω–æ –ø–æ—Ä—Ç—Ñ–æ–ª–∏–æ")
                elif tool_result == "[PRICING]":
                    special_actions.append(("pricing", None))
                    step_tool_results.append(f"{tc['name']}: –ø–æ–∫–∞–∑–∞–Ω –ø—Ä–∞–π—Å")
                elif tool_result == "[PAYMENT]":
                    special_actions.append(("payment", None))
                    step_tool_results.append(f"{tc['name']}: –ø–æ–∫–∞–∑–∞–Ω–∞ –æ–ø–ª–∞—Ç–∞")
                elif tool_result == "[AI_BRIEF_GENERATED]":
                    special_actions.append(("ai_brief", None))
                    step_tool_results.append(f"{tc['name']}: AI —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–ª –±—Ä–∏—Ñ –ø—Ä–æ–µ–∫—Ç–∞")
                else:
                    step_tool_results.append(f"{tc['name']}: {tool_result}")
                    all_tool_results.append({"tool": tc["name"], "result": tool_result})
            
            tool_results_text = "\n\n".join(step_tool_results)
            current_messages.append({
                "role": "model",
                "parts": [{"text": f"–Ø –≤—ã–∑–≤–∞–ª –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:\n{tool_results_text}"}]
            })
            current_messages.append({
                "role": "user",
                "parts": [{"text": "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã. –ï—Å–ª–∏ –Ω—É–∂–Ω–æ ‚Äî –≤—ã–∑–æ–≤–∏ –µ—â—ë –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞. –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî —Å—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –∫–ª–∏–µ–Ω—Ç—É."}]
            })
            
            logger.info(f"Agentic loop step {step+1}: {len(result['tool_calls'])} tool calls")
        
        final_response = await self.generate_response(
            messages=current_messages,
            thinking_level=effective_thinking,
            query_context=query_context,
            dynamic_system_prompt=dynamic_system_prompt
        )
        
        return {
            "text": final_response,
            "special_actions": special_actions,
            "all_tool_results": all_tool_results
        }

    async def analyze_complex_query(
        self,
        query: str,
        context: Optional[str] = None
    ) -> str:
        prompt = query
        if context:
            prompt = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}\n\n–í–æ–ø—Ä–æ—Å: {query}"
        
        messages = [{"role": "user", "parts": [{"text": prompt}]}]
        return await self.generate_response(messages, thinking_level="high")
    
    async def quick_response(self, query: str) -> str:
        messages = [{"role": "user", "parts": [{"text": query}]}]
        return await self.generate_response(messages, thinking_level="low")


TOOL_DECLARATIONS = [
    {
        "name": "calculate_price",
        "description": "–†–∞—Å—Å—á–∏—Ç–∞—Ç—å —Å—Ç–æ–∏–º–æ—Å—Ç—å —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ Telegram Mini App –ø–æ –Ω–∞–±–æ—Ä—É —Ñ—É–Ω–∫—Ü–∏–π. –í—ã–∑—ã–≤–∞–π –∫–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç —Ü–µ–Ω—É –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ —Ñ—É–Ω–∫—Ü–∏–π –∏–ª–∏ —Ö–æ—á–µ—Ç –ø–æ—Å—á–∏—Ç–∞—Ç—å —Å—Ç–æ–∏–º–æ—Å—Ç—å.",
        "parameters": {
            "type": "object",
            "properties": {
                "features": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "–°–ø–∏—Å–æ–∫ —Ñ—É–Ω–∫—Ü–∏–π: catalog, cart, auth, search, favorites, reviews, payments, subscriptions, installments, delivery, pickup, express, push, chat, video, loyalty, promo, referral, analytics, admin, crm, booking, queue, calendar, ai, ai_rec, auto_reply, smart_search, voice, tg_bot, whatsapp, maps, sms, email, 1c, api, progress"
                }
            },
            "required": ["features"]
        }
    },
    {
        "name": "show_portfolio",
        "description": "–ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–∏–º–µ—Ä—ã —Ä–∞–±–æ—Ç –∏–∑ –ø–æ—Ä—Ç—Ñ–æ–ª–∏–æ. –í—ã–∑—ã–≤–∞–π –∫–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç —Ö–æ—á–µ—Ç —É–≤–∏–¥–µ—Ç—å –ø—Ä–∏–º–µ—Ä—ã, –∫–µ–π—Å—ã –∏–ª–∏ –ø–æ—Ä—Ç—Ñ–æ–ª–∏–æ.",
        "parameters": {
            "type": "object",
            "properties": {
                "category": {
                    "type": "string",
                    "enum": ["ecommerce", "services", "fintech", "education", "all"],
                    "description": "–ö–∞—Ç–µ–≥–æ—Ä–∏—è –ø–æ—Ä—Ç—Ñ–æ–ª–∏–æ"
                }
            },
            "required": ["category"]
        }
    },
    {
        "name": "show_pricing",
        "description": "–ü–æ–∫–∞–∑–∞—Ç—å –æ–±—â–∏–π –ø—Ä–∞–π—Å-–ª–∏—Å—Ç —É—Å–ª—É–≥. –í—ã–∑—ã–≤–∞–π –∫–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –æ —Ü–µ–Ω–∞—Ö –≤ –æ–±—â–µ–º.",
        "parameters": {
            "type": "object",
            "properties": {}
        }
    },
    {
        "name": "create_lead",
        "description": "–°–æ–∑–¥–∞—Ç—å –∑–∞—è–≤–∫—É –æ—Ç –∫–ª–∏–µ–Ω—Ç–∞. –í—ã–∑—ã–≤–∞–π –∫–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç –≥–æ–≤–æ—Ä–∏—Ç —á—Ç–æ —Ö–æ—á–µ—Ç –∑–∞–∫–∞–∑–∞—Ç—å, –≥–æ—Ç–æ–≤ –Ω–∞—á–∞—Ç—å, –ø—Ä–æ—Å–∏—Ç —Å–≤—è–∑–∞—Ç—å—Å—è —Å –Ω–∏–º.",
        "parameters": {
            "type": "object",
            "properties": {
                "interest": {
                    "type": "string",
                    "description": "–ß—Ç–æ –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç –∫–ª–∏–µ–Ω—Ç–∞"
                },
                "budget": {
                    "type": "string",
                    "description": "–ü—Ä–∏–º–µ—Ä–Ω—ã–π –±—é–¥–∂–µ—Ç, –µ—Å–ª–∏ –æ–∑–≤—É—á–µ–Ω"
                }
            },
            "required": ["interest"]
        }
    },
    {
        "name": "show_payment_info",
        "description": "–ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∫–≤–∏–∑–∏—Ç—ã –¥–ª—è –æ–ø–ª–∞—Ç—ã. –í—ã–∑—ã–≤–∞–π –∫–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç –≥–æ—Ç–æ–≤ –æ–ø–ª–∞—Ç–∏—Ç—å –∏–ª–∏ —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –∫–∞–∫ –æ–ø–ª–∞—Ç–∏—Ç—å.",
        "parameters": {
            "type": "object",
            "properties": {}
        }
    },
    {
        "name": "calculate_roi",
        "description": "–†–∞—Å—Å—á–∏—Ç–∞—Ç—å –æ–∫—É–ø–∞–µ–º–æ—Å—Ç—å (ROI) Telegram Mini App –¥–ª—è –±–∏–∑–Ω–µ—Å–∞ –∫–ª–∏–µ–Ω—Ç–∞. –í—ã–∑—ã–≤–∞–π –∫–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç —Å–æ–º–Ω–µ–≤–∞–µ—Ç—Å—è –≤ –≤—ã–≥–æ–¥–µ, —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç '–∑–∞—á–µ–º –º–Ω–µ —ç—Ç–æ' –∏–ª–∏ '–æ–∫—É–ø–∏—Ç—Å—è –ª–∏'.",
        "parameters": {
            "type": "object",
            "properties": {
                "business_type": {
                    "type": "string",
                    "description": "–¢–∏–ø –±–∏–∑–Ω–µ—Å–∞: restaurant, shop, beauty, education, services, fitness, delivery, other"
                },
                "monthly_clients": {
                    "type": "integer",
                    "description": "–ü—Ä–∏–º–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∏–µ–Ω—Ç–æ–≤ –≤ –º–µ—Å—è—Ü"
                },
                "avg_check": {
                    "type": "integer",
                    "description": "–°—Ä–µ–¥–Ω–∏–π —á–µ–∫ –≤ —Ä—É–±–ª—è—Ö"
                },
                "app_cost": {
                    "type": "integer",
                    "description": "–°—Ç–æ–∏–º–æ—Å—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –≤ —Ä—É–±–ª—è—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 150000). –ò—Å–ø–æ–ª—å–∑—É–π –µ—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç —É–∂–µ –æ–±—Å—É–¥–∏–ª –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –±—é–¥–∂–µ—Ç."
                }
            },
            "required": ["business_type"]
        }
    },
    {
        "name": "compare_plans",
        "description": "–°—Ä–∞–≤–Ω–∏—Ç—å —Ç–∞—Ä–∏—Ñ–Ω—ã–µ –ø–ª–∞–Ω—ã –∏ –ø–∞–∫–µ—Ç—ã —É—Å–ª—É–≥. –í—ã–∑—ã–≤–∞–π –∫–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç –Ω–µ –º–æ–∂–µ—Ç –≤—ã–±—Ä–∞—Ç—å –º–µ–∂–¥—É –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏ –∏–ª–∏ –ø—Ä–æ—Å–∏—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ.",
        "parameters": {
            "type": "object",
            "properties": {
                "plan_type": {
                    "type": "string",
                    "enum": ["packages", "subscriptions", "custom_vs_template"],
                    "description": "–ß—Ç–æ —Å—Ä–∞–≤–Ω–∏—Ç—å: packages (MVP/Standard/Premium), subscriptions (–ø–æ–¥–ø–∏—Å–∫–∏), custom_vs_template (–∑–∞–∫–∞–∑–Ω–∞—è vs —à–∞–±–ª–æ–Ω)"
                }
            },
            "required": ["plan_type"]
        }
    },
    {
        "name": "schedule_consultation",
        "description": "–ó–∞–ø–∏—Å–∞—Ç—å –∫–ª–∏–µ–Ω—Ç–∞ –Ω–∞ –±–µ—Å–ø–ª–∞—Ç–Ω—É—é –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é —Å –º–µ–Ω–µ–¥–∂–µ—Ä–æ–º. –í—ã–∑—ã–≤–∞–π –∫–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç —Ö–æ—á–µ—Ç –æ–±—Å—É–¥–∏—Ç—å –ø—Ä–æ–µ–∫—Ç –ø–æ–¥—Ä–æ–±–Ω–µ–µ, –∑–∞–¥–∞—ë—Ç —Å–ª–æ–∂–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ –≥–æ—Ç–æ–≤ –∫ —Å–æ–∑–≤–æ–Ω—É.",
        "parameters": {
            "type": "object",
            "properties": {
                "preferred_time": {
                    "type": "string",
                    "description": "–ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º–æ–µ –≤—Ä–µ–º—è (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ)"
                },
                "topic": {
                    "type": "string",
                    "description": "–¢–µ–º–∞ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏"
                }
            },
            "required": ["topic"]
        }
    },
    {
        "name": "generate_brief",
        "description": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –±—Ä–∏—Ñ –ø—Ä–æ–µ–∫—Ç–∞ –∏ –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å PDF –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ. –í—ã–∑—ã–≤–∞–π –∫–æ–≥–¥–∞ –∏–∑ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ —Ç—ã —Å–æ–±—Ä–∞–ª –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–æ–µ–∫—Ç–µ –∫–ª–∏–µ–Ω—Ç–∞ (–º–∏–Ω–∏–º—É–º: —Ç–∏–ø –ø—Ä–æ–µ–∫—Ç–∞ + –±—é–¥–∂–µ—Ç/–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç). –ó–∞–ø–æ–ª–Ω–∏ –º–∞–∫—Å–∏–º—É–º –ø–æ–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–∏–∞–ª–æ–≥–∞. AI –¥–æ–ª–∂–µ–Ω –ü–†–û–ê–ö–¢–ò–í–ù–û –ø—Ä–µ–¥–ª–∞–≥–∞—Ç—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –±—Ä–∏—Ñ, –∫–æ–≥–¥–∞ –ø–æ–Ω–∏–º–∞–µ—Ç –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏ –∫–ª–∏–µ–Ω—Ç–∞.",
        "parameters": {
            "type": "object",
            "properties": {
                "project_type": {
                    "type": "string",
                    "enum": ["shop", "restaurant", "beauty", "fitness", "medical", "education", "services", "custom"],
                    "description": "–¢–∏–ø –ø—Ä–æ–µ–∫—Ç–∞: shop=–º–∞–≥–∞–∑–∏–Ω, restaurant=—Ä–µ—Å—Ç–æ—Ä–∞–Ω/–¥–æ—Å—Ç–∞–≤–∫–∞, beauty=—Å–∞–ª–æ–Ω –∫—Ä–∞—Å–æ—Ç—ã, fitness=—Ñ–∏—Ç–Ω–µ—Å, medical=–º–µ–¥–∏—Ü–∏–Ω–∞, education=–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ, services=—É—Å–ª—É–≥–∏, custom=–∫–∞—Å—Ç–æ–º–Ω—ã–π"
                },
                "audience": {
                    "type": "string",
                    "enum": ["b2c_young", "b2c_adult", "b2c_premium", "b2c_mass", "b2b", "mixed"],
                    "description": "–ê—É–¥–∏—Ç–æ—Ä–∏—è: b2c_young=–º–æ–ª–æ–¥—ë–∂—å 18-35, b2c_adult=—Å–µ–º–µ–π–Ω—ã–µ 25-45, b2c_premium=–ø—Ä–µ–º–∏—É–º, b2c_mass=–º–∞—Å—Å–æ–≤—ã–π, b2b=–±–∏–∑–Ω–µ—Å, mixed=—Å–º–µ—à–∞–Ω–Ω–∞—è"
                },
                "key_features": {
                    "type": "string",
                    "enum": ["catalog_cart", "booking", "payments", "loyalty", "ai_bot", "delivery", "analytics", "crm"],
                    "description": "–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: catalog_cart=–∫–∞—Ç–∞–ª–æ–≥+–∫–æ—Ä–∑–∏–Ω–∞, booking=–±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ, payments=–æ–ø–ª–∞—Ç–∞, loyalty=–ª–æ—è–ª—å–Ω–æ—Å—Ç—å, ai_bot=AI –±–æ—Ç, delivery=–¥–æ—Å—Ç–∞–≤–∫–∞, analytics=–∞–Ω–∞–ª–∏—Ç–∏–∫–∞, crm=CRM"
                },
                "design_pref": {
                    "type": "string",
                    "enum": ["minimal", "modern", "premium", "bright", "corporate", "custom_design"],
                    "description": "–°—Ç–∏–ª—å –¥–∏–∑–∞–π–Ω–∞: minimal, modern, premium, bright=—è—Ä–∫–∏–π, corporate, custom_design=—Å–≤–æ–π –º–∞–∫–µ—Ç"
                },
                "integrations": {
                    "type": "string",
                    "enum": ["tg_payments", "bank_cards", "1c", "crm_ext", "maps", "sms_email", "none"],
                    "description": "–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏: tg_payments=Telegram Stars, bank_cards=–∫–∞—Ä—Ç—ã, 1c, crm_ext=Bitrix/AmoCRM, maps, sms_email, none"
                },
                "budget_timeline": {
                    "type": "string",
                    "enum": ["fast_cheap", "balanced", "quality", "mvp_first"],
                    "description": "–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: fast_cheap=–±—ã—Å—Ç—Ä–æ –∏ –±—é–¥–∂–µ—Ç–Ω–æ, balanced=–±–∞–ª–∞–Ω—Å, quality=–º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ, mvp_first=—Å–Ω–∞—á–∞–ª–∞ MVP"
                },
                "project_description": {
                    "type": "string",
                    "description": "–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ –∫–ª–∏–µ–Ω—Ç–∞ —Å–≤–æ–∏–º–∏ —Å–ª–æ–≤–∞–º–∏"
                }
            },
            "required": ["project_type", "budget_timeline"]
        }
    },
    {
        "name": "check_discount",
        "description": "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Å–∫–∏–¥–∫–∏ –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞. –í—ã–∑—ã–≤–∞–π –∫–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –ø—Ä–æ —Å–∫–∏–¥–∫–∏, –∞–∫—Ü–∏–∏, –ø—Ä–æ–º–æ–∫–æ–¥—ã.",
        "parameters": {
            "type": "object",
            "properties": {}
        }
    },
    {
        "name": "show_available_slots",
        "description": "–ü–æ–∫–∞–∑–∞—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Å–ª–æ—Ç—ã –¥–ª—è –∑–∞–ø–∏—Å–∏ –Ω–∞ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é. –í—ã–∑—ã–≤–∞–π –∫–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç —Ö–æ—á–µ—Ç –∑–∞–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –≤—Ä–µ–º—è –∏–ª–∏ —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –∫–æ–≥–¥–∞ –º–æ–∂–Ω–æ —Å–æ–∑–≤–æ–Ω–∏—Ç—å—Å—è.",
        "parameters": {
            "type": "object",
            "properties": {}
        }
    },
    {
        "name": "book_consultation_slot",
        "description": "–ó–∞–±—Ä–æ–Ω–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Å–ª–æ—Ç –¥–ª—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏. –í—ã–∑—ã–≤–∞–π –∫–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç –≤—ã–±—Ä–∞–ª –¥–∞—Ç—É –∏ –≤—Ä–µ–º—è –¥–ª—è —Å–æ–∑–≤–æ–Ω–∞.",
        "parameters": {
            "type": "object",
            "properties": {
                "date": {
                    "type": "string",
                    "description": "–î–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD"
                },
                "time": {
                    "type": "string",
                    "description": "–í—Ä–µ–º—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ HH:MM"
                },
                "topic": {
                    "type": "string",
                    "description": "–¢–µ–º–∞ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏"
                }
            },
            "required": ["date", "time"]
        }
    },
    {
        "name": "show_social_links",
        "description": "–ü–æ–∫–∞–∑–∞—Ç—å —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å–æ—Ü—Å–µ—Ç–∏ WEB4TG Studio. –í—ã–∑—ã–≤–∞–π –∫–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –æ —Å–æ—Ü—Å–µ—Ç—è—Ö, YouTube, Instagram, TikTok, –∏–ª–∏ —Ö–æ—á–µ—Ç –ø–æ–¥–ø–∏—Å–∞—Ç—å—Å—è.",
        "parameters": {
            "type": "object",
            "properties": {
                "include_tasks": {
                    "type": "boolean",
                    "description": "–ü–æ–∫–∞–∑–∞—Ç—å –∑–∞–¥–∞–Ω–∏—è –∑–∞ –º–æ–Ω–µ—Ç—ã (–ø–æ–¥–ø–∏—Å–∫–∞ = –º–æ–Ω–µ—Ç—ã)"
                }
            }
        }
    },
    {
        "name": "search_knowledge_base",
        "description": "–ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π WEB4TG Studio. –í—ã–∑—ã–≤–∞–π –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ –Ω–∞–π—Ç–∏ —Ç–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö, –ø—Ä–æ—Ü–µ—Å—Å–∞—Ö, –≥–∞—Ä–∞–Ω—Ç–∏—è—Ö, —É—Å–ª–æ–≤–∏—è—Ö —Ä–∞–±–æ—Ç—ã –∏–ª–∏ –¥–µ—Ç–∞–ª—è—Ö, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –ø—Ä–∞–π—Å–µ. –ü–æ–ª–µ–∑–Ω–æ –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã.",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å ‚Äî —á—Ç–æ –∏–º–µ–Ω–Ω–æ –Ω—É–∂–Ω–æ –Ω–∞–π—Ç–∏ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π"
                },
                "limit": {
                    "type": "integer",
                    "description": "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 3)"
                }
            },
            "required": ["query"]
        }
    },
    {
        "name": "remember_client_info",
        "description": "–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–ª–∏–µ–Ω—Ç–µ –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ –±—É–¥—É—â–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤. –í—ã–∑—ã–≤–∞–π –∫–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–µ—Ç –æ —Å–≤–æ—ë–º –±–∏–∑–Ω–µ—Å–µ, –±—é–¥–∂–µ—Ç–µ, —Å—Ä–æ–∫–∞—Ö, –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—è—Ö –∏–ª–∏ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è—Ö. –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–æ–º–Ω–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –º–µ–∂–¥—É —Å–µ—Å—Å–∏—è–º–∏.",
        "parameters": {
            "type": "object",
            "properties": {
                "industry": {
                    "type": "string",
                    "description": "–û—Ç—Ä–∞—Å–ª—å –±–∏–∑–Ω–µ—Å–∞: shop, restaurant, beauty, fitness, medical, education, delivery, services, other"
                },
                "budget_range": {
                    "type": "string",
                    "description": "–ü—Ä–∏–º–µ—Ä–Ω—ã–π –±—é–¥–∂–µ—Ç –∫–ª–∏–µ–Ω—Ç–∞, –Ω–∞–ø—Ä–∏–º–µ—Ä '150-200–∫' –∏–ª–∏ '–¥–æ 300–∫'"
                },
                "timeline": {
                    "type": "string",
                    "description": "–ñ–µ–ª–∞–µ–º—ã–µ —Å—Ä–æ–∫–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä '—Å—Ä–æ—á–Ω–æ', '2 –Ω–µ–¥–µ–ª–∏', '–∫ –ª–µ—Ç—É'"
                },
                "needs": {
                    "type": "string",
                    "description": "–ö–ª—é—á–µ–≤—ã–µ –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏ –∫–ª–∏–µ–Ω—Ç–∞ (—á—Ç–æ —Ö–æ—á–µ—Ç —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å)"
                },
                "objections": {
                    "type": "string",
                    "description": "–û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ —Å–æ–º–Ω–µ–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞"
                },
                "business_name": {
                    "type": "string",
                    "description": "–ù–∞–∑–≤–∞–Ω–∏–µ –±–∏–∑–Ω–µ—Å–∞ –∫–ª–∏–µ–Ω—Ç–∞, –µ—Å–ª–∏ –æ–∑–≤—É—á–µ–Ω–æ"
                },
                "city": {
                    "type": "string",
                    "description": "–ì–æ—Ä–æ–¥ –∫–ª–∏–µ–Ω—Ç–∞, –µ—Å–ª–∏ –æ–∑–≤—É—á–µ–Ω"
                }
            }
        }
    },
    {
        "name": "compare_with_competitors",
        "description": "–°—Ä–∞–≤–Ω–∏—Ç—å —Ä–∞–∑—Ä–∞–±–æ—Ç–∫—É –≤ WEB4TG Studio —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞–º–∏. –í—ã–∑—ã–≤–∞–π –∫–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç —É–ø–æ–º–∏–Ω–∞–µ—Ç –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤, —Ñ—Ä–∏–ª–∞–Ω—Å–µ—Ä–æ–≤, –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä—ã –∏–ª–∏ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—É—é —Ä–∞–∑—Ä–∞–±–æ—Ç–∫—É.",
        "parameters": {
            "type": "object",
            "properties": {
                "competitor_type": {
                    "type": "string",
                    "enum": ["freelancer", "agency", "constructor", "nocode", "inhouse", "general"],
                    "description": "–¢–∏–ø –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"
                }
            },
            "required": ["competitor_type"]
        }
    },
    {
        "name": "request_screenshot",
        "description": "–ü–æ–ø—Ä–æ—Å–∏—Ç—å –∫–ª–∏–µ–Ω—Ç–∞ –ø—Ä–∏—Å–ª–∞—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç –∏–ª–∏ —Ñ–æ—Ç–æ –¥–ª—è –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞. –í—ã–∑—ã–≤–∞–π –∫–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç –æ–ø–∏—Å—ã–≤–∞–µ—Ç —Å–≤–æ–π —Å–∞–π—Ç/–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ/–±–∏–∑–Ω–µ—Å —Å–ª–æ–≤–∞–º–∏, –Ω–æ –≤–∏–∑—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞—Å—Ç –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç. –¢–∞–∫–∂–µ –≤—ã–∑—ã–≤–∞–π –∫–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç —É–ø–æ–º–∏–Ω–∞–µ—Ç –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞ ‚Äî –ø—Ä–µ–¥–ª–æ–∂–∏ –ø—Ä–∏—Å–ª–∞—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è.",
        "parameters": {
            "type": "object",
            "properties": {
                "analysis_type": {
                    "type": "string",
                    "enum": ["app_audit", "website_audit", "competitor_analysis", "design_review", "business_photo", "document_review"],
                    "description": "–¢–∏–ø –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: app_audit=–∞—É–¥–∏—Ç –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, website_audit=–∞—É–¥–∏—Ç —Å–∞–π—Ç–∞, competitor_analysis=–∞–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞, design_review=—Ä–µ–≤—å—é –¥–∏–∑–∞–π–Ω–∞, business_photo=—Ñ–æ—Ç–æ –±–∏–∑–Ω–µ—Å–∞, document_review=–∞–Ω–∞–ª–∏–∑ –¢–ó/–¥–æ–∫—É–º–µ–Ω—Ç–∞"
                },
                "reason": {
                    "type": "string",
                    "description": "–ü–æ—á–µ–º—É –≤–∏–∑—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –±—É–¥–µ—Ç –ø–æ–ª–µ–∑–µ–Ω –∫–ª–∏–µ–Ω—Ç—É"
                }
            },
            "required": ["analysis_type", "reason"]
        }
    }
]


ai_client = AIClient()
