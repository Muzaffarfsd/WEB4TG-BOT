"""Proactive Engagement Engine ‚Äî trigger-based dialog initiation, behavioral signals, predictive engagement."""

import asyncio
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple

from src.database import get_connection, DATABASE_URL
from src.leads import lead_manager
from src.config import config
from psycopg2.extras import RealDictCursor

logger = logging.getLogger(__name__)

TRIGGER_TYPES = {
    "funnel_stall": "–ö–ª–∏–µ–Ω—Ç –∑–∞–≤–∏—Å –Ω–∞ —ç—Ç–∞–ø–µ –≤–æ—Ä–æ–Ω–∫–∏",
    "engagement_drop": "–†–µ–∑–∫–æ–µ –ø–∞–¥–µ–Ω–∏–µ –≤–æ–≤–ª–µ—á—ë–Ω–Ω–æ—Å—Ç–∏",
    "high_intent_no_action": "–í—ã—Å–æ–∫–∏–π –∏–Ω—Ç–µ—Ä–µ—Å, –Ω–æ –Ω–µ—Ç –¥–µ–π—Å—Ç–≤–∏—è",
    "cart_abandonment": "–ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –±–µ–∑ –∑–∞—è–≤–∫–∏",
    "comeback_window": "–û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞",
    "optimal_time_window": "–õ—É—á—à–µ–µ –≤—Ä–µ–º—è –¥–ª—è –∫–æ–Ω—Ç–∞–∫—Ç–∞",
    "competitor_research": "–£–ø–æ–º–∏–Ω–∞–Ω–∏–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ + –º–æ–ª—á–∞–Ω–∏–µ",
    "warm_reactivation": "–†–µ–∞–∫—Ç–∏–≤–∞—Ü–∏—è —Ç—ë–ø–ª–æ–≥–æ –ª–∏–¥–∞",
}

MAX_PROACTIVE_PER_4H = 1
MAX_PROACTIVE_PER_DAY = 3
DELIVERY_HOUR_START = 9
DELIVERY_HOUR_END = 20

TRIGGER_PROMPTS = {
    "funnel_stall": """–¢—ã ‚Äî –ê–ª–µ–∫—Å, –∂–∏–≤–æ–π –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç WEB4TG Studio. –ù–ï –±–æ—Ç, –ù–ï –∞–≤—Ç–æ–æ—Ç–≤–µ—Ç—á–∏–∫.

–°–ò–¢–£–ê–¶–ò–Ø: –ö–ª–∏–µ–Ω—Ç –∞–∫—Ç–∏–≤–Ω–æ –æ–±—â–∞–ª—Å—è, –∏–∑—É—á–∞–ª —É—Å–ª—É–≥–∏, –Ω–æ –≤–Ω–µ–∑–∞–ø–Ω–æ –∑–∞–º–æ–ª—á–∞–ª –Ω–∞ —ç—Ç–∞–ø–µ "{stage}".
–≠—Ç–∞–ø –≤–æ—Ä–æ–Ω–∫–∏: {stage}
–í—Ä–µ–º—è –º–æ–ª—á–∞–Ω–∏—è: {hours_silent}—á

–ö–æ–Ω—Ç–µ–∫—Å—Ç:
{context}

{client_signals}

–ó–ê–î–ê–ß–ê: –ú—è–≥–∫–æ –≤–µ—Ä–Ω—É—Ç—å –∫–ª–∏–µ–Ω—Ç–∞, –ø—Ä–µ–¥–ª–æ–∂–∏–≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –ø–æ–º–æ—â—å –ø–æ —Ç–æ–º—É, –Ω–∞ —á—ë–º –æ–Ω –æ—Å—Ç–∞–Ω–æ–≤–∏–ª—Å—è.

–°–¢–†–ê–¢–ï–ì–ò–Ø:
- –ù–µ —Å–ø—Ä–∞—à–∏–≤–∞–π "–≤—Å—ë –ª–∏ –æ–∫" ‚Äî –¥–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫—É –ø–æ —Ç–µ–º–µ, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–π –∫–ª–∏–µ–Ω—Ç –∑–∞—Å—Ç—Ä—è–ª
- –ï—Å–ª–∏ –∑–∞—Å—Ç—Ä—è–ª –Ω–∞ —Ü–µ–Ω–∞—Ö ‚Äî –ø—Ä–µ–¥–ª–æ–∂–∏ —Ä–∞—Å—á—ë—Ç ROI –∏–ª–∏ —Ä–∞—Å—Å—Ä–æ—á–∫—É
- –ï—Å–ª–∏ –Ω–∞ –ø–æ—Ä—Ç—Ñ–æ–ª–∏–æ ‚Äî –ø—Ä–µ–¥–ª–æ–∂–∏ –∫–µ–π—Å –∏–∑ –µ–≥–æ –Ω–∏—à–∏
- –ï—Å–ª–∏ –Ω–∞ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ ‚Äî —É–ø—Ä–æ—Å—Ç–∏ —à–∞–≥ (–º–∏–Ω–∏-–∑–≤–æ–Ω–æ–∫ 5 –º–∏–Ω)

–§–û–†–ú–ê–¢: 2-3 –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –ë–µ–∑ markdown, –±–µ–∑ —Å–ø–∏—Å–∫–æ–≤. –û–¥–Ω–æ emoji –º–∞–∫—Å–∏–º—É–º –≤ –∫–æ–Ω—Ü–µ.

–ù–∞–ø–∏—à–∏ –¢–û–õ–¨–ö–û —Ç–µ–∫—Å—Ç.""",

    "engagement_drop": """–¢—ã ‚Äî –ê–ª–µ–∫—Å, –∂–∏–≤–æ–π –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç WEB4TG Studio. –ù–ï –±–æ—Ç, –ù–ï –∞–≤—Ç–æ–æ—Ç–≤–µ—Ç—á–∏–∫.

–°–ò–¢–£–ê–¶–ò–Ø: –ö–ª–∏–µ–Ω—Ç –±—ã–ª –∞–∫—Ç–∏–≤–µ–Ω (–æ—Ç–≤–µ—á–∞–ª –±—ã—Å—Ç—Ä–æ, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã), –Ω–æ —Å–∫–æ—Ä–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–æ–≤ —Ä–µ–∑–∫–æ —É–ø–∞–ª–∞.
–ë—ã–ª–æ: {prev_speed} –º–∏–Ω/–æ—Ç–≤–µ—Ç ‚Üí –°—Ç–∞–ª–æ: {curr_speed} –º–∏–Ω/–æ—Ç–≤–µ—Ç
–ü–æ—Å–ª–µ–¥–Ω–µ–µ –¥–µ–π—Å—Ç–≤–∏–µ: {last_action}

–ö–æ–Ω—Ç–µ–∫—Å—Ç:
{context}

{client_signals}

–ó–ê–î–ê–ß–ê: –í–µ—Ä–Ω—É—Ç—å –≤–æ–≤–ª–µ—á—ë–Ω–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ –º–∏–∫—Ä–æ-—Ü–µ–Ω–Ω–æ—Å—Ç—å, —Å–≤—è–∑–∞–Ω–Ω—É—é —Å –ø–æ—Å–ª–µ–¥–Ω–∏–º –∏–Ω—Ç–µ—Ä–µ—Å–æ–º –∫–ª–∏–µ–Ω—Ç–∞.

–°–¢–†–ê–¢–ï–ì–ò–Ø:
- –ù–∞—á–Ω–∏ —Å —á–µ–≥–æ-—Ç–æ –ø–æ–ª–µ–∑–Ω–æ–≥–æ –ø–æ —Ç–µ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
- –ù–µ —É–ø–æ–º–∏–Ω–∞–π —á—Ç–æ –∑–∞–º–µ—Ç–∏–ª "—Å–Ω–∏–∂–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"
- –ü—Ä–µ–¥–ª–æ–∂–∏ –±—ã—Å—Ç—Ä—ã–π —Å–ª–µ–¥—É—é—â–∏–π —à–∞–≥ (2 –º–∏–Ω—É—Ç—ã)

–§–û–†–ú–ê–¢: 2-3 –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –ë–µ–∑ markdown. –û–¥–Ω–æ emoji –º–∞–∫—Å–∏–º—É–º.

–ù–∞–ø–∏—à–∏ –¢–û–õ–¨–ö–û —Ç–µ–∫—Å—Ç.""",

    "high_intent_no_action": """–¢—ã ‚Äî –ê–ª–µ–∫—Å, –∂–∏–≤–æ–π –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç WEB4TG Studio. –ù–ï –±–æ—Ç, –ù–ï –∞–≤—Ç–æ–æ—Ç–≤–µ—Ç—á–∏–∫.

–°–ò–¢–£–ê–¶–ò–Ø: –ö–ª–∏–µ–Ω—Ç –ø–æ–∫–∞–∑–∞–ª –≤—ã—Å–æ–∫–∏–π –∏–Ω—Ç–µ—Ä–µ—Å (propensity {score}/100), –Ω–æ –Ω–µ —Å–¥–µ–ª–∞–ª –∫–ª—é—á–µ–≤–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ.
Propensity score: {score}/100
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–ª: {tools_used}
–ù–ï —Å–¥–µ–ª–∞–ª: {missing_action}

–ö–æ–Ω—Ç–µ–∫—Å—Ç:
{context}

{client_signals}

–ó–ê–î–ê–ß–ê: –ü–æ–¥—Ç–æ–ª–∫–Ω—É—Ç—å –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —à–∞–≥—É —á–µ—Ä–µ–∑ —Å–Ω–∏–∂–µ–Ω–∏–µ –±–∞—Ä—å–µ—Ä–∞.

–°–¢–†–ê–¢–ï–ì–ò–Ø:
- –ü–æ–∫–∞–∂–∏ —á—Ç–æ —Ç—ã –£–ñ–ï –ø–æ–¥–≥–æ—Ç–æ–≤–∏–ª —á—Ç–æ-—Ç–æ –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞
- –ü—Ä–µ–¥–ª–æ–∂–∏ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π/–ª—ë–≥–∫–∏–π —à–∞–≥ –∫ –¥–µ–π—Å—Ç–≤–∏—é
- –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–∏–Ω—Ü–∏–ø "—è —Å–¥–µ–ª–∞–ª –∑–∞ —Ç–µ–±—è" ‚Äî –∫–ª–∏–µ–Ω—Ç—É –æ—Å—Ç–∞—ë—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å

–§–û–†–ú–ê–¢: 2-3 –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –ë–µ–∑ markdown. –û–¥–Ω–æ emoji –º–∞–∫—Å–∏–º—É–º.

–ù–∞–ø–∏—à–∏ –¢–û–õ–¨–ö–û —Ç–µ–∫—Å—Ç.""",

    "cart_abandonment": """–¢—ã ‚Äî –ê–ª–µ–∫—Å, –∂–∏–≤–æ–π –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç WEB4TG Studio. –ù–ï –±–æ—Ç, –ù–ï –∞–≤—Ç–æ–æ—Ç–≤–µ—Ç—á–∏–∫.

–°–ò–¢–£–ê–¶–ò–Ø: –ö–ª–∏–µ–Ω—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä (—Ä–∞—Å—Å—á–∏—Ç–∞–ª —Å—Ç–æ–∏–º–æ—Å—Ç—å {cost}‚ÇΩ), –Ω–æ –Ω–µ –æ—Å—Ç–∞–≤–∏–ª –∑–∞—è–≤–∫—É.
–†–∞—Å—Å—á–∏—Ç–∞–Ω–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: {cost}‚ÇΩ
–í—ã–±—Ä–∞–Ω–Ω—ã–µ —Ñ–∏—á–∏: {features}

–ö–æ–Ω—Ç–µ–∫—Å—Ç:
{context}

{client_signals}

–ó–ê–î–ê–ß–ê: –í–µ—Ä–Ω—É—Ç—å –∫–ª–∏–µ–Ω—Ç–∞, –æ–±—Ä–∞–±–æ—Ç–∞–≤ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏–µ –ø–æ —Ü–µ–Ω–µ.

–°–¢–†–ê–¢–ï–ì–ò–Ø:
- –£–ø–æ–º—è–Ω–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é —Å—É–º–º—É ‚Äî –ø–æ–∫–∞–∂–∏ —á—Ç–æ –ø–æ–º–Ω–∏—à—å
- –ü—Ä–µ–¥–ª–æ–∂–∏ —Ä–∞—Å—Å—Ä–æ—á–∫—É –∏–ª–∏ MVP-–≤–∞—Ä–∏–∞–Ω—Ç
- –ü–æ–∫–∞–∂–∏ ROI: "–∑–∞ X–∫/–º–µ—Å –æ–∫—É–ø–∏—Ç—Å—è –∑–∞ Y –¥–Ω–µ–π"
- –ù–µ –¥–∞–≤–∞–π —Å–∫–∏–¥–∫—É —Å—Ä–∞–∑—É, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –≤–æ–∑—Ä–∞–∂–∞–µ—Ç

–§–û–†–ú–ê–¢: 2-3 –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –ë–µ–∑ markdown. –û–¥–Ω–æ emoji –º–∞–∫—Å–∏–º—É–º.

–ù–∞–ø–∏—à–∏ –¢–û–õ–¨–ö–û —Ç–µ–∫—Å—Ç.""",

    "comeback_window": """–¢—ã ‚Äî –ê–ª–µ–∫—Å, –∂–∏–≤–æ–π –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç WEB4TG Studio. –ù–ï –±–æ—Ç, –ù–ï –∞–≤—Ç–æ–æ—Ç–≤–µ—Ç—á–∏–∫.

–°–ò–¢–£–ê–¶–ò–Ø: –ö–ª–∏–µ–Ω—Ç –≤–µ—Ä–Ω—É–ª—Å—è –ø–æ—Å–ª–µ –ø–∞—É–∑—ã {days_away} –¥–Ω–µ–π, –Ω–æ –µ—â—ë –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–ø–∏—Å–∞–ª. –≠—Ç–æ –æ–∫–Ω–æ –¥–ª—è –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—ã.
–î–Ω–µ–π –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è: {days_away}
–ü—Ä–µ–∂–Ω–∏–π –∏–Ω—Ç–µ—Ä–µ—Å: {prev_interest}

–ö–æ–Ω—Ç–µ–∫—Å—Ç:
{context}

{client_signals}

–ó–ê–î–ê–ß–ê: –¢—ë–ø–ª–æ –ø–æ–ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –∏ –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å —á—Ç–æ-—Ç–æ –ù–û–í–û–ï —Å –º–æ–º–µ–Ω—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±—â–µ–Ω–∏—è.

–°–¢–†–ê–¢–ï–ì–ò–Ø:
- –ù–µ —É–ø–æ–º–∏–Ω–∞–π —á—Ç–æ "–¥–∞–≤–Ω–æ –Ω–µ –ø–∏—Å–∞–ª" –ø—Ä—è–º–æ
- –†–∞—Å—Å–∫–∞–∂–∏ –æ –Ω–æ–≤–æ–º –∫–µ–π—Å–µ/—Ñ–∏—á–µ/–∞–∫—Ü–∏–∏, –∫–æ—Ç–æ—Ä–∞—è –ø–æ—è–≤–∏–ª–∞—Å—å
- –ü–æ–∫–∞–∂–∏ —á—Ç–æ –ø–æ–º–Ω–∏—à—å –∫–æ–Ω—Ç–µ–∫—Å—Ç (–Ω–∏—à–∞, –∑–∞–¥–∞—á–∞ –∫–ª–∏–µ–Ω—Ç–∞)

–§–û–†–ú–ê–¢: 2-3 –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –ë–µ–∑ markdown. –û–¥–Ω–æ emoji –º–∞–∫—Å–∏–º—É–º.

–ù–∞–ø–∏—à–∏ –¢–û–õ–¨–ö–û —Ç–µ–∫—Å—Ç.""",

    "optimal_time_window": """–¢—ã ‚Äî –ê–ª–µ–∫—Å, –∂–∏–≤–æ–π –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç WEB4TG Studio. –ù–ï –±–æ—Ç, –ù–ï –∞–≤—Ç–æ–æ—Ç–≤–µ—Ç—á–∏–∫.

–°–ò–¢–£–ê–¶–ò–Ø: –ê–Ω–∞–ª–∏–∑ –ø–æ–∫–∞–∑–∞–ª, —á—Ç–æ —Å–µ–π—á–∞—Å –ª—É—á—à–µ–µ –≤—Ä–µ–º—è –¥–ª—è –∫–æ–Ω—Ç–∞–∫—Ç–∞ —Å –∫–ª–∏–µ–Ω—Ç–æ–º (–æ–Ω –æ–±—ã—á–Ω–æ –∞–∫—Ç–∏–≤–µ–Ω –≤ —ç—Ç–æ –≤—Ä–µ–º—è).
–û–±—ã—á–Ω–æ–µ –≤—Ä–µ–º—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏: {active_hours}
–¢–µ–∫—É—â–∏–π —ç—Ç–∞–ø: {stage}

–ö–æ–Ω—Ç–µ–∫—Å—Ç:
{context}

{client_signals}

–ó–ê–î–ê–ß–ê: –û—Ç–ø—Ä–∞–≤–∏—Ç—å —Ü–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –º–æ–º–µ–Ω—Ç.

–°–¢–†–ê–¢–ï–ì–ò–Ø:
- –ù–∞—á–Ω–∏ —Å –º–∏–∫—Ä–æ-–ø–æ–ª—å–∑—ã: —Ñ–∞–∫—Ç, —Å–æ–≤–µ—Ç, –∫–µ–π—Å –∏–∑ –µ–≥–æ –Ω–∏—à–∏
- –ü—Ä–∏–≤—è–∂–∏ –∫ –Ω–µ—Ä–µ—à—ë–Ω–Ω–æ–π –∑–∞–¥–∞—á–µ –∫–ª–∏–µ–Ω—Ç–∞
- –ü—Ä–µ–¥–ª–æ–∂–∏ –ª—ë–≥–∫–∏–π —Å–ª–µ–¥—É—é—â–∏–π —à–∞–≥

–§–û–†–ú–ê–¢: 2-3 –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –ë–µ–∑ markdown. –û–¥–Ω–æ emoji –º–∞–∫—Å–∏–º—É–º.

–ù–∞–ø–∏—à–∏ –¢–û–õ–¨–ö–û —Ç–µ–∫—Å—Ç.""",

    "competitor_research": """–¢—ã ‚Äî –ê–ª–µ–∫—Å, –∂–∏–≤–æ–π –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç WEB4TG Studio. –ù–ï –±–æ—Ç, –ù–ï –∞–≤—Ç–æ–æ—Ç–≤–µ—Ç—á–∏–∫.

–°–ò–¢–£–ê–¶–ò–Ø: –ö–ª–∏–µ–Ω—Ç —É–ø–æ–º–∏–Ω–∞–ª –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤/–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã ("{competitor_mention}"), –ø–æ—Ç–æ–º –∑–∞–º–æ–ª—á–∞–ª ‚Äî –≤–µ—Ä–æ—è—Ç–Ω–æ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç.
–£–ø–æ–º—è–Ω—É—Ç—ã–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã: {competitor_mention}
–ú–æ–ª—á–∏—Ç: {hours_silent}—á

–ö–æ–Ω—Ç–µ–∫—Å—Ç:
{context}

{client_signals}

–ó–ê–î–ê–ß–ê: –ü–æ–º–æ—á—å –∫–ª–∏–µ–Ω—Ç—É —Å—Ä–∞–≤–Ω–∏—Ç—å, –Ω–µ –∫—Ä–∏—Ç–∏–∫—É—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤.

–°–¢–†–ê–¢–ï–ì–ò–Ø:
- –ü—Ä–µ–¥–ª–æ–∂–∏ –æ–±—ä–µ–∫—Ç–∏–≤–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ ("—Å–æ—Å—Ç–∞–≤–∏–ª —Ç–∞–±–ª–∏—Ü—É –ø–ª—é—Å–æ–≤ –∏ –º–∏–Ω—É—Å–æ–≤")
- –ü–æ–¥—á–µ—Ä–∫–Ω–∏ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ WEB4TG (—Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è, —Å—Ä–æ–∫–∏ 7-15 –¥–Ω–µ–π, –¥–æ–≥–æ–≤–æ—Ä)
- –ù–µ –∫—Ä–∏—Ç–∏–∫—É–π –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã, –≤–æ–ø—Ä–æ—Å–∞–º–∏ –ø–æ–¥–≤–µ–¥–∏ –∫ –≤—ã–≤–æ–¥—É

–§–û–†–ú–ê–¢: 2-3 –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –ë–µ–∑ markdown. –û–¥–Ω–æ emoji –º–∞–∫—Å–∏–º—É–º.

–ù–∞–ø–∏—à–∏ –¢–û–õ–¨–ö–û —Ç–µ–∫—Å—Ç.""",

    "warm_reactivation": """–¢—ã ‚Äî –ê–ª–µ–∫—Å, –∂–∏–≤–æ–π –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç WEB4TG Studio. –ù–ï –±–æ—Ç, –ù–ï –∞–≤—Ç–æ–æ—Ç–≤–µ—Ç—á–∏–∫.

–°–ò–¢–£–ê–¶–ò–Ø: –¢—ë–ø–ª—ã–π –ª–∏–¥ (score {score}/100) –Ω–µ –ø—Ä–æ—è–≤–ª—è–ª –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å {days_inactive} –¥–Ω–µ–π. –ü–æ—Ä–∞ —Ä–µ–∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å.
Score: {score}/100
–î–Ω–µ–π –Ω–µ–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏: {days_inactive}
–ü–æ—Å–ª–µ–¥–Ω–µ–µ –¥–µ–π—Å—Ç–≤–∏–µ: {last_action}

–ö–æ–Ω—Ç–µ–∫—Å—Ç:
{context}

{client_signals}

–ó–ê–î–ê–ß–ê: –†–µ–∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å —Ç—ë–ø–ª—ã–π –ª–∏–¥ —á–µ—Ä–µ–∑ –Ω–æ–≤—É—é —Ü–µ–Ω–Ω–æ—Å—Ç—å.

–°–¢–†–ê–¢–ï–ì–ò–Ø:
- –ü—Ä–µ–¥–ª–æ–∂–∏ —á—Ç–æ-—Ç–æ –Ω–æ–≤–æ–µ, —á–µ–≥–æ –Ω–µ –±—ã–ª–æ —Ä–∞–Ω—å—à–µ (—Å–≤–µ–∂–∏–π –∫–µ–π—Å, –Ω–æ–≤–∞—è —Ñ–∏—á–∞, –∞–∫—Ü–∏—è)
- –£–ø–æ–º—è–Ω–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –≤—ã–≥–æ–¥—É –¥–ª—è –µ–≥–æ –±–∏–∑–Ω–µ—Å–∞
- –°–Ω–∏–∑—å –±–∞—Ä—å–µ—Ä –≤—Ö–æ–¥–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ ("–ø—Ä–æ—Å—Ç–æ –≥–ª—è–Ω—å 2 –º–∏–Ω")

–§–û–†–ú–ê–¢: 2-3 –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –ë–µ–∑ markdown. –û–¥–Ω–æ emoji –º–∞–∫—Å–∏–º—É–º.

–ù–∞–ø–∏—à–∏ –¢–û–õ–¨–ö–û —Ç–µ–∫—Å—Ç.""",
}


def _build_client_signals(user_id: int) -> str:
    signals = []
    try:
        lead = lead_manager.get_lead(user_id)
        if lead:
            if lead.score and lead.score >= 50:
                signals.append("–°–ò–ì–ù–ê–õ: –ì–æ—Ä—è—á–∏–π –ª–∏–¥")
            elif lead.score and lead.score >= 25:
                signals.append("–°–ò–ì–ù–ê–õ: –¢—ë–ø–ª—ã–π –ª–∏–¥")
            if lead.business_type:
                signals.append(f"–ù–ò–®–ê: {lead.business_type}")
            if lead.budget:
                signals.append(f"–ë–Æ–î–ñ–ï–¢: {lead.budget}")
    except Exception:
        pass

    try:
        from src.session import get_client_profile
        profile = get_client_profile(user_id)
        if profile:
            if profile.get("business_type"):
                signals.append(f"–ë–ò–ó–ù–ï–°: {profile['business_type']}")
            if profile.get("pain_points"):
                signals.append(f"–ë–û–õ–ò: {profile['pain_points']}")
    except Exception:
        pass

    try:
        from src.propensity import propensity_scorer
        score = propensity_scorer.calculate_score(user_id)
        if score:
            signals.append(f"PROPENSITY: {score}/100")
    except Exception:
        pass

    return "\n".join(signals) if signals else "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –∫–ª–∏–µ–Ω—Ç–µ"


class ProactiveEngagementEngine:
    def __init__(self):
        self._init_db()

    def _init_db(self):
        if not DATABASE_URL:
            logger.warning("DATABASE_URL not set, proactive engagement disabled")
            return

        try:
            with get_connection() as conn:
                with conn.cursor() as cur:
                    cur.execute("""
                        CREATE TABLE IF NOT EXISTS behavioral_signals (
                            id SERIAL PRIMARY KEY,
                            user_id BIGINT NOT NULL,
                            avg_response_speed_min FLOAT DEFAULT 0,
                            prev_response_speed_min FLOAT DEFAULT 0,
                            session_frequency_days FLOAT DEFAULT 0,
                            last_active_hour INTEGER,
                            peak_active_hours VARCHAR(50),
                            engagement_velocity FLOAT DEFAULT 0,
                            prev_engagement_velocity FLOAT DEFAULT 0,
                            last_funnel_stage VARCHAR(50),
                            funnel_stage_entered_at TIMESTAMP,
                            competitor_mentioned BOOLEAN DEFAULT FALSE,
                            competitor_context TEXT,
                            last_tool_used VARCHAR(50),
                            calculator_result INTEGER,
                            calculator_features TEXT,
                            days_since_last_activity FLOAT DEFAULT 0,
                            total_sessions INTEGER DEFAULT 0,
                            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                            UNIQUE(user_id)
                        )
                    """)
                    cur.execute("""
                        CREATE INDEX IF NOT EXISTS idx_behavioral_user
                        ON behavioral_signals(user_id)
                    """)
                    cur.execute("""
                        CREATE TABLE IF NOT EXISTS trigger_history (
                            id SERIAL PRIMARY KEY,
                            user_id BIGINT NOT NULL,
                            trigger_type VARCHAR(50) NOT NULL,
                            trigger_score FLOAT DEFAULT 0,
                            message_text TEXT,
                            status VARCHAR(20) DEFAULT 'sent',
                            responded BOOLEAN DEFAULT FALSE,
                            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                        )
                    """)
                    cur.execute("""
                        CREATE INDEX IF NOT EXISTS idx_trigger_user_created
                        ON trigger_history(user_id, created_at)
                    """)
                    cur.execute("""
                        CREATE INDEX IF NOT EXISTS idx_trigger_status
                        ON trigger_history(status, created_at)
                    """)
            logger.info("Proactive engagement tables initialized")
        except Exception as e:
            logger.error(f"Failed to init proactive engagement tables: {e}")

    def update_behavioral_signals(self, user_id: int, event_type: str = "message", **kwargs):
        if not DATABASE_URL:
            return
        try:
            with get_connection() as conn:
                with conn.cursor() as cur:
                    cur.execute("""
                        INSERT INTO behavioral_signals (user_id)
                        VALUES (%s)
                        ON CONFLICT (user_id) DO NOTHING
                    """, (user_id,))

                    updates = ["updated_at = CURRENT_TIMESTAMP"]
                    params = []

                    if event_type == "message":
                        cur.execute("""
                            SELECT avg_response_speed_min FROM behavioral_signals WHERE user_id = %s
                        """, (user_id,))
                        row = cur.fetchone()
                        old_speed = row[0] if row and row[0] else 0
                        new_speed = kwargs.get("response_speed_min", 0)
                        if new_speed > 0:
                            updates.append("prev_response_speed_min = avg_response_speed_min")
                            avg = (old_speed * 0.7 + new_speed * 0.3) if old_speed > 0 else new_speed
                            updates.append("avg_response_speed_min = %s")
                            params.append(avg)

                        now_hour = datetime.utcnow().hour
                        tz_offset = kwargs.get("tz_offset", 0)
                        local_hour = (now_hour + tz_offset) % 24
                        updates.append("last_active_hour = %s")
                        params.append(local_hour)

                    if event_type == "funnel_stage":
                        stage = kwargs.get("stage", "")
                        if stage:
                            updates.append("last_funnel_stage = %s")
                            params.append(stage)
                            updates.append("funnel_stage_entered_at = CURRENT_TIMESTAMP")

                    if event_type == "competitor_mention":
                        updates.append("competitor_mentioned = TRUE")
                        mention = kwargs.get("competitor_context", "")
                        if mention:
                            updates.append("competitor_context = %s")
                            params.append(mention[:500])

                    if event_type == "calculator_used":
                        result = kwargs.get("cost", 0)
                        features = kwargs.get("features", "")
                        if result:
                            updates.append("calculator_result = %s")
                            params.append(result)
                        if features:
                            updates.append("calculator_features = %s")
                            params.append(features[:500])
                        updates.append("last_tool_used = 'calculator'")

                    if event_type in ("tool_portfolio", "tool_pricing", "tool_brief", "tool_consultation"):
                        updates.append("last_tool_used = %s")
                        params.append(event_type)

                    cur.execute("""
                        SELECT engagement_velocity FROM behavioral_signals WHERE user_id = %s
                    """, (user_id,))
                    ev_row = cur.fetchone()
                    old_ev = ev_row[0] if ev_row and ev_row[0] else 0

                    try:
                        from src.propensity import propensity_scorer
                        new_score = propensity_scorer.calculate_score(user_id)
                        if new_score is not None:
                            updates.append("prev_engagement_velocity = engagement_velocity")
                            updates.append("engagement_velocity = %s")
                            params.append(float(new_score))
                    except Exception:
                        pass

                    updates.append("days_since_last_activity = 0")

                    params.append(user_id)
                    cur.execute(
                        f"UPDATE behavioral_signals SET {', '.join(updates)} WHERE user_id = %s",
                        params
                    )
        except Exception as e:
            logger.error(f"Failed to update behavioral signals for {user_id}: {e}")

    def _check_anti_spam(self, user_id: int) -> bool:
        if not DATABASE_URL:
            return False
        try:
            with get_connection() as conn:
                with conn.cursor() as cur:
                    cur.execute("""
                        SELECT COUNT(*) FROM trigger_history
                        WHERE user_id = %s AND created_at > NOW() - INTERVAL '4 hours'
                        AND status = 'sent'
                    """, (user_id,))
                    count_4h = cur.fetchone()[0]
                    if count_4h >= MAX_PROACTIVE_PER_4H:
                        return False

                    cur.execute("""
                        SELECT COUNT(*) FROM trigger_history
                        WHERE user_id = %s AND created_at > NOW() - INTERVAL '24 hours'
                        AND status = 'sent'
                    """, (user_id,))
                    count_24h = cur.fetchone()[0]
                    if count_24h >= MAX_PROACTIVE_PER_DAY:
                        return False

                    return True
        except Exception as e:
            logger.error(f"Anti-spam check failed for {user_id}: {e}")
            return False

    def _is_delivery_window(self, user_id: int) -> bool:
        try:
            from src.session import get_client_profile
            profile = get_client_profile(user_id)
            tz_offset = 0
            if profile and profile.get("timezone_offset") is not None:
                tz_offset = profile["timezone_offset"]
            local_hour = (datetime.utcnow().hour + tz_offset) % 24
            return DELIVERY_HOUR_START <= local_hour < DELIVERY_HOUR_END
        except Exception:
            current_hour = datetime.utcnow().hour
            return 6 <= current_hour < 18

    def _is_user_eligible(self, user_id: int) -> bool:
        try:
            from src.followup import follow_up_manager
            with get_connection() as conn:
                with conn.cursor() as cur:
                    cur.execute("""
                        SELECT id FROM follow_ups
                        WHERE user_id = %s AND status = 'paused'
                    """, (user_id,))
                    if cur.fetchone():
                        return False

                    cur.execute("""
                        SELECT is_blocked FROM bot_users
                        WHERE user_id = %s
                    """, (user_id,))
                    row = cur.fetchone()
                    if row and row[0]:
                        return False

                    cur.execute("""
                        SELECT id FROM follow_ups
                        WHERE user_id = %s AND status = 'scheduled'
                        AND scheduled_at <= NOW() + INTERVAL '2 hours'
                    """, (user_id,))
                    if cur.fetchone():
                        return False

            return True
        except Exception:
            return True

    def _calculate_predictive_score(self, signals: Dict) -> float:
        score = 0.0

        response_speed = signals.get("avg_response_speed_min", 0) or 0
        prev_speed = signals.get("prev_response_speed_min", 0) or 0
        if prev_speed > 0 and response_speed > 0:
            speed_ratio = response_speed / prev_speed
            if speed_ratio > 2.0:
                score += 15
            elif speed_ratio > 1.5:
                score += 10
            elif speed_ratio < 0.8:
                score += 5

        velocity = signals.get("engagement_velocity", 0) or 0
        prev_velocity = signals.get("prev_engagement_velocity", 0) or 0
        if prev_velocity > 0:
            velocity_change = (velocity - prev_velocity) / prev_velocity
            if velocity_change < -0.3:
                score += 15
            elif velocity_change < -0.1:
                score += 8

        days_inactive = signals.get("days_since_last_activity", 0) or 0
        if 1 <= days_inactive <= 3:
            score += 20
        elif 3 < days_inactive <= 7:
            score += 15
        elif 7 < days_inactive <= 14:
            score += 10
        elif days_inactive > 14:
            score += 5

        sessions = signals.get("total_sessions", 0) or 0
        if sessions >= 3:
            score += 10
        elif sessions >= 2:
            score += 5

        tool = signals.get("last_tool_used", "") or ""
        if tool in ("calculator", "tool_brief"):
            score += 15
        elif tool in ("tool_consultation", "tool_pricing"):
            score += 10
        elif tool in ("tool_portfolio",):
            score += 5

        if signals.get("calculator_result"):
            score += 10
        if signals.get("competitor_mentioned"):
            score += 10

        return min(score, 100)

    def evaluate_triggers(self) -> List[Dict]:
        if not DATABASE_URL:
            return []

        triggered = []
        try:
            with get_connection() as conn:
                with conn.cursor(cursor_factory=RealDictCursor) as cur:
                    cur.execute("""
                        SELECT bs.*,
                               im.total_messages, im.last_interaction, im.tools_used,
                               im.calculator_uses, im.portfolio_views, im.pricing_views,
                               im.lead_submitted, im.consultation_requested, im.payment_viewed,
                               im.last_score as propensity_score,
                               im.brief_uses, im.compare_uses
                        FROM behavioral_signals bs
                        LEFT JOIN interaction_metrics im ON bs.user_id = im.user_id
                        WHERE bs.updated_at > NOW() - INTERVAL '30 days'
                    """)
                    users = cur.fetchall()

            for u in users:
                user_id = u["user_id"]

                if not self._is_user_eligible(user_id):
                    continue
                if not self._check_anti_spam(user_id):
                    continue
                if not self._is_delivery_window(user_id):
                    continue

                triggers = self._detect_triggers(u)
                if triggers:
                    best = max(triggers, key=lambda t: t["score"])
                    triggered.append(best)

        except Exception as e:
            logger.error(f"Failed to evaluate triggers: {e}")

        triggered.sort(key=lambda t: t["score"], reverse=True)
        return triggered[:20]

    def _detect_triggers(self, u: Dict) -> List[Dict]:
        triggers = []
        user_id = u["user_id"]
        last_interaction = u.get("last_interaction")
        propensity = u.get("propensity_score", 0) or 0

        if last_interaction:
            hours_since = (datetime.utcnow() - last_interaction).total_seconds() / 3600
        else:
            hours_since = 999

        stage = u.get("last_funnel_stage", "") or ""
        stage_entered = u.get("funnel_stage_entered_at")
        if stage and stage_entered:
            stage_hours = (datetime.utcnow() - stage_entered).total_seconds() / 3600
            if stage_hours >= 6 and hours_since >= 4:
                score = self._calculate_predictive_score(u)
                if score >= 25:
                    triggers.append({
                        "user_id": user_id,
                        "trigger_type": "funnel_stall",
                        "score": score,
                        "params": {
                            "stage": stage,
                            "hours_silent": int(hours_since),
                        }
                    })

        avg_speed = u.get("avg_response_speed_min", 0) or 0
        prev_speed = u.get("prev_response_speed_min", 0) or 0
        if prev_speed > 0 and avg_speed > 0:
            ratio = avg_speed / prev_speed
            if ratio > 2.0 and hours_since >= 3:
                score = self._calculate_predictive_score(u)
                if score >= 20:
                    triggers.append({
                        "user_id": user_id,
                        "trigger_type": "engagement_drop",
                        "score": score + 5,
                        "params": {
                            "prev_speed": round(prev_speed, 1),
                            "curr_speed": round(avg_speed, 1),
                            "last_action": u.get("last_tool_used", "—Å–æ–æ–±—â–µ–Ω–∏–µ"),
                        }
                    })

        if propensity >= 40:
            lead_submitted = u.get("lead_submitted", False)
            consultation = u.get("consultation_requested", False)
            if not lead_submitted and not consultation and hours_since >= 6:
                tools = []
                if u.get("calculator_uses", 0) > 0:
                    tools.append("–∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä")
                if u.get("portfolio_views", 0) > 0:
                    tools.append("–ø–æ—Ä—Ç—Ñ–æ–ª–∏–æ")
                if u.get("pricing_views", 0) > 0:
                    tools.append("—Ü–µ–Ω—ã")
                if u.get("brief_uses", 0) > 0:
                    tools.append("–±—Ä–∏—Ñ")

                missing = "–∑–∞—è–≤–∫–∞/–∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è"
                if not lead_submitted:
                    missing = "–∑–∞—è–≤–∫–∞"
                if not consultation:
                    missing = "–∑–∞–ø–∏—Å—å –Ω–∞ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é"

                score = self._calculate_predictive_score(u)
                if score >= 30:
                    triggers.append({
                        "user_id": user_id,
                        "trigger_type": "high_intent_no_action",
                        "score": score + 10,
                        "params": {
                            "score": propensity,
                            "tools_used": ", ".join(tools) if tools else "–Ω–µ—Ç",
                            "missing_action": missing,
                        }
                    })

        calc_uses = u.get("calculator_uses", 0) or 0
        calc_result = u.get("calculator_result", 0) or 0
        lead_submitted = u.get("lead_submitted", False)
        if calc_uses > 0 and calc_result > 0 and not lead_submitted and hours_since >= 4:
            score = self._calculate_predictive_score(u)
            if score >= 20:
                triggers.append({
                    "user_id": user_id,
                    "trigger_type": "cart_abandonment",
                    "score": score + 15,
                    "params": {
                        "cost": calc_result,
                        "features": u.get("calculator_features", ""),
                    }
                })

        days_inactive = hours_since / 24
        if 3 <= days_inactive <= 14 and propensity >= 20:
            score = self._calculate_predictive_score(u)
            if score >= 20:
                triggers.append({
                    "user_id": user_id,
                    "trigger_type": "comeback_window",
                    "score": score,
                    "params": {
                        "days_away": int(days_inactive),
                        "prev_interest": stage or "–æ–±—â–∏–π –∏–Ω—Ç–µ—Ä–µ—Å",
                    }
                })

        peak_hours = u.get("peak_active_hours", "") or ""
        last_hour = u.get("last_active_hour")
        if last_hour is not None:
            try:
                from src.session import get_client_profile
                profile = get_client_profile(user_id)
                tz_offset = 0
                if profile and profile.get("timezone_offset") is not None:
                    tz_offset = profile["timezone_offset"]
                local_hour = (datetime.utcnow().hour + tz_offset) % 24
                if abs(local_hour - last_hour) <= 1 and hours_since >= 12 and propensity >= 30:
                    score = self._calculate_predictive_score(u)
                    triggers.append({
                        "user_id": user_id,
                        "trigger_type": "optimal_time_window",
                        "score": score + 5,
                        "params": {
                            "active_hours": f"{last_hour}:00",
                            "stage": stage or "–∏–Ω—Ç–µ—Ä–µ—Å",
                        }
                    })
            except Exception:
                pass

        if u.get("competitor_mentioned") and hours_since >= 6 and hours_since <= 72:
            score = self._calculate_predictive_score(u)
            if score >= 15:
                triggers.append({
                    "user_id": user_id,
                    "trigger_type": "competitor_research",
                    "score": score + 10,
                    "params": {
                        "competitor_mention": u.get("competitor_context", "–∫–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã")[:200],
                        "hours_silent": int(hours_since),
                    }
                })

        if 7 <= days_inactive <= 30 and 25 <= propensity <= 60:
            score = self._calculate_predictive_score(u)
            if score >= 15:
                triggers.append({
                    "user_id": user_id,
                    "trigger_type": "warm_reactivation",
                    "score": score,
                    "params": {
                        "score": propensity,
                        "days_inactive": int(days_inactive),
                        "last_action": u.get("last_tool_used", "—Å–æ–æ–±—â–µ–Ω–∏–µ"),
                    }
                })

        return triggers

    async def generate_trigger_message(self, trigger: Dict) -> str:
        trigger_type = trigger["trigger_type"]
        user_id = trigger["user_id"]
        params = trigger.get("params", {})

        try:
            messages = lead_manager.get_conversation_history(user_id, limit=8)
            context_parts = []
            for msg in messages[-6:]:
                role_label = "–ö–ª–∏–µ–Ω—Ç" if msg.role == "user" else "–ê–ª–µ–∫—Å"
                context_parts.append(f"{role_label}: {msg.content[:250]}")
            context = "\n".join(context_parts) if context_parts else "–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ –º–∏–Ω–∏–º–∞–ª–µ–Ω."

            client_signals = _build_client_signals(user_id)

            prompt_template = TRIGGER_PROMPTS.get(trigger_type, TRIGGER_PROMPTS["funnel_stall"])
            format_params = {
                "context": context,
                "client_signals": client_signals,
                **params,
            }
            for key in ("stage", "hours_silent", "prev_speed", "curr_speed",
                         "last_action", "score", "tools_used", "missing_action",
                         "cost", "features", "days_away", "prev_interest",
                         "active_hours", "competitor_mention", "days_inactive"):
                if key not in format_params:
                    format_params[key] = ""

            prompt = prompt_template.format(**format_params)

            from src.ai_client import ai_client
            result = await ai_client.generate_response(
                messages=[{"role": "user", "parts": [{"text": prompt}]}],
                thinking_level="low"
            )

            if result:
                text = result.strip().strip('"').strip("'")
                if len(text) > 20:
                    return text

        except Exception as e:
            logger.error(f"Failed to generate trigger message for {user_id} ({trigger_type}): {e}")

        return self._get_fallback_message(trigger_type, params)

    def _get_fallback_message(self, trigger_type: str, params: Dict) -> str:
        fallbacks = {
            "funnel_stall": "–ö—Å—Ç–∞—Ç–∏, –ø–æ –ø–æ–≤–æ–¥—É —Ç–≤–æ–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞ ‚Äî –ø–æ–¥–≥–æ—Ç–æ–≤–∏–ª –ø—Ä–∏–º–µ—Ä–Ω—ã–π –ø–ª–∞–Ω. –ú–æ–≥—É —Å–∫–∏–Ω—É—Ç—å? –ó–∞–π–º—ë—Ç 2 –º–∏–Ω—É—Ç—ã –≥–ª—è–Ω—É—Ç—å üòä",
            "engagement_drop": "–í—Å–ø–æ–º–Ω–∏–ª –ø—Ä–æ —Ç–µ–±—è ‚Äî —É –Ω–∞—Å —Å–≤–µ–∂–∏–π –∫–µ–π—Å –∏–∑ –ø–æ—Ö–æ–∂–µ–π –Ω–∏—à–∏, +47 –∑–∞–∫–∞–∑–æ–≤ –∑–∞ –º–µ—Å—è—Ü. –ò–Ω—Ç–µ—Ä–µ—Å–Ω–æ?",
            "high_intent_no_action": "–Ø —Ç—É—Ç –ø—Ä–∏–∫–∏–Ω—É–ª –ø—Ä–∏–º–µ—Ä–Ω—ã–π ROI –¥–ª—è —Ç–≤–æ–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞ ‚Äî —Ü–∏—Ñ—Ä—ã –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ –ø–æ–ª—É—á–∏–ª–∏—Å—å. –°–∫–∏–Ω—É—Ç—å?",
            "cart_abandonment": f"–ü–æ —Ç–≤–æ–µ–º—É —Ä–∞—Å—á—ë—Ç—É –Ω–∞ {params.get('cost', '')}‚ÇΩ ‚Äî –∫—Å—Ç–∞—Ç–∏, –µ—Å—Ç—å —Ä–∞—Å—Å—Ä–æ—á–∫–∞ –æ—Ç 35% –ø—Ä–µ–¥–æ–ø–ª–∞—Ç—ã. –≠—Ç–æ –º–µ–Ω—å—à–µ, —á–µ–º –∑–∞—Ä–ø–ª–∞—Ç–∞ —Å—Ç–∞–∂—ë—Ä–∞ –∑–∞ –º–µ—Å—è—Ü)",
            "comeback_window": "–£ –Ω–∞—Å –ø–æ—è–≤–∏–ª–∞—Å—å –Ω–æ–≤–∞—è —Ñ–∏—à–∫–∞ ‚Äî MVP –∑–∞ 7 –¥–Ω–µ–π. –û–¥–∏–Ω –∫–ª–∏–µ–Ω—Ç –æ–∫—É–ø–∏–ª –∑–∞ –ø–µ—Ä–≤—É—é –Ω–µ–¥–µ–ª—é. –ï—Å–ª–∏ —Ö–æ—á–µ—à—å –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ ‚Äî –Ω–∞–ø–∏—à–∏)",
            "optimal_time_window": "–ú–∏–Ω–∏-–∞–ø–ø—ã –≤ —Å—Ä–µ–¥–Ω–µ–º —É–≤–µ–ª–∏—á–∏–≤–∞—é—Ç –∫–æ–Ω–≤–µ—Ä—Å–∏—é –Ω–∞ 35%. –ú–æ–≥—É –ø–æ–∫–∞–∑–∞—Ç—å –∫–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è —Ç–≤–æ–µ–π –Ω–∏—à–∏",
            "competitor_research": "–°–æ—Å—Ç–∞–≤–∏–ª —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—É—é —Ç–∞–±–ª–∏—Ü—É ‚Äî –º–∏–Ω–∏-–∞–ø–ø vs –¥—Ä—É–≥–∏–µ —Ä–µ—à–µ–Ω–∏—è. –¢–∞–º –≤–∏–¥–Ω–æ —Ä–∞–∑–Ω–∏—Ü—É –≤ —Å—Ä–æ–∫–∞—Ö –∏ —Å—Ç–æ–∏–º–æ—Å—Ç–∏. –°–∫–∏–Ω—É—Ç—å?",
            "warm_reactivation": "–î–∞–≤–Ω–æ –Ω–µ –æ–±—â–∞–ª–∏—Å—å! –£ –Ω–∞—Å —Ç—É—Ç –ø–æ—è–≤–∏–ª–∏—Å—å –Ω–æ–≤—ã–µ –∫–µ–π—Å—ã ‚Äî –¥—É–º–∞—é, —Ç–µ–±–µ –±—É–¥–µ—Ç –ø–æ–ª–µ–∑–Ω–æ –≥–ª—è–Ω—É—Ç—å)",
        }
        return fallbacks.get(trigger_type, fallbacks["funnel_stall"])

    def record_trigger_sent(self, user_id: int, trigger_type: str, score: float, message: str):
        if not DATABASE_URL:
            return
        try:
            with get_connection() as conn:
                with conn.cursor() as cur:
                    cur.execute("""
                        INSERT INTO trigger_history (user_id, trigger_type, trigger_score, message_text, status)
                        VALUES (%s, %s, %s, %s, 'sent')
                    """, (user_id, trigger_type, score, message[:2000]))
        except Exception as e:
            logger.error(f"Failed to record trigger for {user_id}: {e}")

    def mark_trigger_responded(self, user_id: int):
        if not DATABASE_URL:
            return
        try:
            with get_connection() as conn:
                with conn.cursor() as cur:
                    cur.execute("""
                        UPDATE trigger_history
                        SET responded = TRUE
                        WHERE user_id = %s AND status = 'sent' AND responded = FALSE
                        AND created_at > NOW() - INTERVAL '7 days'
                    """, (user_id,))
        except Exception as e:
            logger.error(f"Failed to mark trigger responded for {user_id}: {e}")

    def get_trigger_stats(self) -> Dict:
        if not DATABASE_URL:
            return {}
        try:
            with get_connection() as conn:
                with conn.cursor(cursor_factory=RealDictCursor) as cur:
                    cur.execute("""
                        SELECT
                            trigger_type,
                            COUNT(*) as total_sent,
                            COUNT(*) FILTER (WHERE responded = TRUE) as responded,
                            ROUND(AVG(trigger_score)::numeric, 1) as avg_score,
                            COUNT(*) FILTER (WHERE created_at > NOW() - INTERVAL '24 hours') as sent_today,
                            COUNT(*) FILTER (WHERE responded = TRUE AND created_at > NOW() - INTERVAL '7 days') as responded_week
                        FROM trigger_history
                        WHERE status = 'sent'
                        GROUP BY trigger_type
                        ORDER BY total_sent DESC
                    """)
                    results = {}
                    for row in cur.fetchall():
                        tt = row["trigger_type"]
                        total = row["total_sent"] or 1
                        results[tt] = {
                            "total": row["total_sent"],
                            "responded": row["responded"],
                            "response_rate": round(row["responded"] / total * 100, 1),
                            "avg_score": float(row["avg_score"]) if row["avg_score"] else 0,
                            "today": row["sent_today"],
                            "responded_week": row["responded_week"],
                        }
                    return results
        except Exception as e:
            logger.error(f"Failed to get trigger stats: {e}")
            return {}

    def get_pending_triggers_count(self) -> int:
        if not DATABASE_URL:
            return 0
        try:
            with get_connection() as conn:
                with conn.cursor() as cur:
                    cur.execute("""
                        SELECT COUNT(DISTINCT user_id) FROM behavioral_signals
                        WHERE updated_at > NOW() - INTERVAL '30 days'
                    """)
                    return cur.fetchone()[0]
        except Exception:
            return 0

    def get_recent_triggers(self, limit: int = 10) -> List[Dict]:
        if not DATABASE_URL:
            return []
        try:
            with get_connection() as conn:
                with conn.cursor(cursor_factory=RealDictCursor) as cur:
                    cur.execute("""
                        SELECT th.user_id, th.trigger_type, th.trigger_score,
                               th.responded, th.created_at,
                               l.first_name, l.username
                        FROM trigger_history th
                        LEFT JOIN leads l ON th.user_id = l.user_id
                        WHERE th.status = 'sent'
                        ORDER BY th.created_at DESC
                        LIMIT %s
                    """, (limit,))
                    return [dict(r) for r in cur.fetchall()]
        except Exception:
            return []

    def get_conversion_metrics(self) -> Dict:
        if not DATABASE_URL:
            return {}
        try:
            with get_connection() as conn:
                with conn.cursor(cursor_factory=RealDictCursor) as cur:
                    cur.execute("""
                        SELECT
                            COUNT(*) as total_triggers,
                            COUNT(*) FILTER (WHERE responded = TRUE) as total_responded,
                            COUNT(DISTINCT user_id) as unique_users,
                            COUNT(DISTINCT user_id) FILTER (WHERE responded = TRUE) as responded_users,
                            ROUND(AVG(trigger_score)::numeric, 1) as avg_trigger_score,
                            COUNT(*) FILTER (WHERE created_at > NOW() - INTERVAL '7 days') as week_triggers,
                            COUNT(*) FILTER (WHERE responded = TRUE AND created_at > NOW() - INTERVAL '7 days') as week_responded
                        FROM trigger_history
                        WHERE status = 'sent'
                    """)
                    row = cur.fetchone()
                    if row:
                        total = row["total_triggers"] or 1
                        week_total = row["week_triggers"] or 1
                        return {
                            "total_triggers": row["total_triggers"],
                            "total_responded": row["total_responded"],
                            "overall_response_rate": round(row["total_responded"] / total * 100, 1),
                            "unique_users": row["unique_users"],
                            "responded_users": row["responded_users"],
                            "avg_score": float(row["avg_trigger_score"]) if row["avg_trigger_score"] else 0,
                            "week_triggers": row["week_triggers"],
                            "week_responded": row["week_responded"],
                            "week_response_rate": round(row["week_responded"] / week_total * 100, 1),
                        }
        except Exception as e:
            logger.error(f"Failed to get conversion metrics: {e}")
        return {}


proactive_engine = ProactiveEngagementEngine()
