import asyncio
import logging
from telegram import Update, InlineKeyboardMarkup, InlineKeyboardButton
from telegram.ext import ContextTypes
from telegram.constants import ChatAction

from src.session import session_manager
from src.config import config
from src.leads import lead_manager
from src.keyboards import get_loyalty_menu_keyboard

from src.handlers.utils import (
    send_typing_action, STRESS_DICTIONARY, apply_stress_marks,
    loyalty_system, MANAGER_CHAT_ID
)

logger = logging.getLogger(__name__)


VOICE_EMOTION_PROMPT = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –æ–∑–≤—É—á–∫–∏ —á–µ—Ä–µ–∑ ElevenLabs v3.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞: –¥–æ–±–∞–≤–∏—Ç—å –Ω–∞—Ç–∏–≤–Ω—ã–µ audio-—Ç–µ–≥–∏ ElevenLabs v3 –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏ –≤—ã—Ä–∞–∑–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∑–≤—É—á–∞–Ω–∏—è.

–î–û–°–¢–£–ü–ù–´–ï –¢–ï–ì–ò v3 (–≤—Å—Ç–∞–≤–ª—è–π –≤ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö –ø–µ—Ä–µ–¥ —Ñ—Ä–∞–∑–æ–π):

–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ:
- [happy] ‚Äî —Ä–∞–¥–æ—Å—Ç–Ω–æ, –ø–æ–∑–∏—Ç–∏–≤–Ω–æ
- [sad] ‚Äî –≥—Ä—É—Å—Ç–Ω–æ, —Å–æ—á—É–≤—Å—Ç–≤–µ–Ω–Ω–æ
- [angry] ‚Äî —Å –Ω–∞–ø–æ—Ä–æ–º, —Ä–µ—à–∏—Ç–µ–ª—å–Ω–æ
- [excited] ‚Äî —Å —ç–Ω—Ç—É–∑–∏–∞–∑–º–æ–º, –≤–æ–æ–¥—É—à–µ–≤–ª—ë–Ω–Ω–æ
- [nervous] ‚Äî —Å –≤–æ–ª–Ω–µ–Ω–∏–µ–º, –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω–æ

–ê–∫—É—Å—Ç–∏—á–µ—Å–∫–∏–µ:
- [whispers] ‚Äî —à—ë–ø–æ—Ç, –∏–Ω—Ç–∏–º–Ω–æ, —Å–µ–∫—Ä–µ—Ç
- [shouts] ‚Äî –≥—Ä–æ–º–∫–æ, –ø—Ä–∏–∑—ã–≤
- [laughs] ‚Äî —Å–º–µ—Ö –ø–µ—Ä–µ–¥ —Ñ—Ä–∞–∑–æ–π
- [giggles] ‚Äî –ª—ë–≥–∫–∏–π —Å–º–µ—à–æ–∫
- [sighs] ‚Äî –≤–∑–¥–æ—Ö (—É—Å—Ç–∞–ª–æ—Å—Ç—å, –æ–±–ª–µ–≥—á–µ–Ω–∏–µ, –∑–∞–¥—É–º—á–∏–≤–æ—Å—Ç—å)

–°—Ç–∏–ª–µ–≤—ã–µ:
- [friendly] ‚Äî –¥—Ä—É–∂–µ–ª—é–±–Ω–æ
- [calm] ‚Äî —Å–ø–æ–∫–æ–π–Ω–æ, —Ä–∞–∑–º–µ—Ä–µ–Ω–Ω–æ
- [confident] ‚Äî —É–≤–µ—Ä–µ–Ω–Ω–æ, –∞–≤—Ç–æ—Ä–∏—Ç–µ—Ç–Ω–æ
- [warm] ‚Äî —Ç–µ–ø–ª–æ, –∑–∞–±–æ—Ç–ª–∏–≤–æ
- [curious] ‚Äî —Å –∏–Ω—Ç–µ—Ä–µ—Å–æ–º, –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω–æ

–ü–†–ê–í–ò–õ–ê:
1. –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è –∏ –∑–Ω–∞–∫–æ–º—Å—Ç–≤–æ: [friendly] –∏–ª–∏ [warm]
2. –¶–µ–Ω—ã, —Ñ–∞–∫—Ç—ã, –≥–∞—Ä–∞–Ω—Ç–∏–∏: [confident]
3. –í—ã–≥–æ–¥—ã –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–µ–π—Å–æ–≤: [excited]
4. –í–æ–ø—Ä–æ—Å—ã –∫ –∫–ª–∏–µ–Ω—Ç—É: [curious]
5. –≠–º–ø–∞—Ç–∏—è –ø—Ä–∏ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è—Ö: [calm] –∏–ª–∏ [warm]
6. –ò–Ω—Å–∞–π—Ç—ã –∏ —Å–µ–∫—Ä–µ—Ç—ã: [whispers] ‚Äî –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∞ "–º–µ–∂–¥—É –Ω–∞–º–∏"
7. –í–ø–µ—á–∞—Ç–ª—è—é—â–∏–µ —Ü–∏—Ñ—Ä—ã: [excited] –ø–µ—Ä–µ–¥ —á–∏—Å–ª–æ–º
8. –ú–∞–∫—Å–∏–º—É–º 3-4 —Ç–µ–≥–∞ –Ω–∞ –∞–±–∑–∞—Ü, –Ω–µ –ø–µ—Ä–µ—É—Å–µ—Ä–¥—Å—Ç–≤—É–π
9. –£–±–µ—Ä–∏ –í–°–Æ markdown —Ä–∞–∑–º–µ—Ç–∫—É: **, *, #, ‚Ä¢, `, _
10. –ó–∞–º–µ–Ω–∏ \\n\\n –Ω–∞ —Ç–æ—á–∫—É –∏ –ø—Ä–æ–±–µ–ª –¥–ª—è –ø–∞—É–∑
11. –ó–∞–º–µ–Ω–∏ \\n –Ω–∞ –∑–∞–ø—è—Ç—É—é –¥–ª—è –ª—ë–≥–∫–∏—Ö –ø–∞—É–∑
12. –£–±–µ—Ä–∏ emoji (–æ–Ω–∏ –Ω–µ –æ–∑–≤—É—á–∏–≤–∞—é—Ç—Å—è)
13. –ù–ï –º–µ–Ω—è–π —Å–º—ã—Å–ª –∏ —Å–ª–æ–≤–∞, —Ç–æ–ª—å–∫–æ –¥–æ–±–∞–≤—å —Ç–µ–≥–∏ –∏ –æ—á–∏—Å—Ç–∏ —Ä–∞–∑–º–µ—Ç–∫—É
14. –ß–∏—Å–ª–∞ –ø–∏—à–∏ —Å–ª–æ–≤–∞–º–∏ –∏–ª–∏ —Å –ø—Ä–æ–±–µ–ª–∞–º–∏ (150 000, –Ω–µ 150000)

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç, –±–µ–∑ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤.

–¢–µ–∫—Å—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏:
"""


async def analyze_emotions_and_prepare_text(text: str) -> str:
    from google import genai
    from google.genai import types
    
    client = genai.Client(api_key=config.gemini_api_key)
    
    try:
        response = await asyncio.to_thread(
            client.models.generate_content,
            model="gemini-2.0-flash",
            contents=[VOICE_EMOTION_PROMPT + text],
            config=types.GenerateContentConfig(
                max_output_tokens=2000,
                temperature=0.3
            )
        )
        
        if response.text:
            return response.text.strip()
    except Exception as e:
        logger.error(f"Emotion analysis error: {e}")
    
    return text


async def generate_voice_response(text: str) -> bytes:
    from elevenlabs import ElevenLabs
    
    client = ElevenLabs(api_key=config.elevenlabs_api_key)
    
    clean_text = text.replace("**", "").replace("*", "").replace("#", "").replace("‚Ä¢", ",")
    clean_text = clean_text.replace("`", "").replace("_", "")
    clean_text = clean_text.replace("\n\n", ". ").replace("\n", ", ")
    
    import re
    clean_text = re.sub(r'[^\w\s\[\].,!?;:\'\"‚Äî‚Äì\-()‚ÇΩ%+=/\\]', '', clean_text)
    
    voice_text = await analyze_emotions_and_prepare_text(clean_text)
    
    voice_text = apply_stress_marks(voice_text)
    
    if len(voice_text) > 4500:
        voice_text = voice_text[:4500].rsplit('.', 1)[0] + '.'
    
    try:
        audio_generator = await asyncio.to_thread(
            client.text_to_speech.convert,
            voice_id=config.elevenlabs_voice_id,
            text=voice_text,
            model_id="eleven_v3",
            output_format="mp3_44100_192",
            voice_settings={
                "stability": 0.4,
                "similarity_boost": 0.8,
                "style": 0.6,
                "use_speaker_boost": True,
            }
        )
        
        audio_bytes = b"".join(audio_generator)
        return audio_bytes
    except Exception as e:
        logger.error(f"ElevenLabs voice generation failed ({type(e).__name__}): {e}")
        raise


async def _transcribe_voice(voice_bytes: bytes) -> str:
    from google import genai
    from google.genai import types
    
    client = genai.Client(api_key=config.gemini_api_key)
    
    audio_part = types.Part.from_bytes(data=bytes(voice_bytes), mime_type="audio/ogg")
    text_part = types.Part(text=(
        "–†–∞—Å—à–∏—Ñ—Ä—É–π —ç—Ç–æ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–æ—Å–ª–æ–≤–Ω–æ. "
        "–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û —Ç–µ–∫—Å—Ç —Ç–æ–≥–æ, —á—Ç–æ —Å–∫–∞–∑–∞–ª —á–µ–ª–æ–≤–µ–∫. "
        "–ë–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π, –±–µ–∑ –∫–∞–≤—ã—á–µ–∫."
    ))
    
    response = await asyncio.to_thread(
        client.models.generate_content,
        model="gemini-2.0-flash",
        contents=[audio_part, text_part],
        config=types.GenerateContentConfig(
            max_output_tokens=500,
            temperature=0.1
        )
    )
    
    if response.text:
        return response.text.strip()
    return ""


async def voice_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user = update.effective_user
    
    typing_task = asyncio.create_task(
        send_typing_action(update, duration=60.0)
    )
    
    try:
        voice = update.message.voice
        file = await context.bot.get_file(voice.file_id)
        voice_bytes = await file.download_as_bytearray()
        
        transcription = await _transcribe_voice(voice_bytes)
        
        if not transcription:
            typing_task.cancel()
            await update.message.reply_text(
                "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑ –∏–ª–∏ –Ω–∞–ø–∏—à–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–º."
            )
            return
        
        logger.info(f"User {user.id} voice transcribed: {transcription[:100]}...")
        
        session = session_manager.get_session(
            user_id=user.id,
            username=user.username,
            first_name=user.first_name
        )
        
        session.add_message("user", transcription, config.max_history_length)
        lead_manager.save_message(user.id, "user", f"[–ì–æ–ª–æ—Å–æ–≤–æ–µ] {transcription}")
        lead_manager.log_event("voice_message", user.id)
        lead_manager.update_activity(user.id)
        
        from src.followup import follow_up_manager
        follow_up_manager.cancel_follow_ups(user.id)
        follow_up_manager.schedule_follow_up(user.id)
        
        from src.context_builder import build_full_context, get_dynamic_buttons
        client_context = build_full_context(user.id, transcription, user.username, user.first_name)
        
        from src.ai_client import ai_client
        
        messages_for_ai = session.get_history()
        if client_context:
            context_msg = {
                "role": "user",
                "parts": [{"text": f"[–°–ò–°–¢–ï–ú–ù–´–ô –ö–û–ù–¢–ï–ö–°–¢ ‚Äî –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–π –∫–ª–∏–µ–Ω—Ç—É, –∏—Å–ø–æ–ª—å–∑—É–π –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏]\n{client_context}"}]
            }
            response_ack = {
                "role": "model",
                "parts": [{"text": "–ü–æ–Ω—è–ª –∫–æ–Ω—Ç–µ–∫—Å—Ç, —É—á—Ç—É –≤ –æ—Ç–≤–µ—Ç–µ."}]
            }
            messages_for_ai = [context_msg, response_ack] + messages_for_ai
        
        from src.handlers.messages import execute_tool_call
        
        async def _tool_executor(tool_name, tool_args):
            return await execute_tool_call(
                tool_name, tool_args,
                user.id, user.username, user.first_name
            )
        
        thinking_level = "high" if len(transcription) > 100 else "medium"
        
        response_text = None
        special_actions = []
        
        try:
            agentic_result = await ai_client.agentic_loop(
                messages=messages_for_ai,
                tool_executor=_tool_executor,
                thinking_level=thinking_level,
                max_steps=4
            )
            
            special_actions = agentic_result.get("special_actions", [])
            
            if special_actions:
                for action_type, action_data in special_actions:
                    if action_type == "portfolio":
                        from src.keyboards import get_portfolio_keyboard
                        from src.knowledge_base import PORTFOLIO_MESSAGE
                        await update.message.reply_text(
                            PORTFOLIO_MESSAGE, parse_mode="Markdown",
                            reply_markup=get_portfolio_keyboard()
                        )
                    elif action_type == "pricing":
                        from src.pricing import get_price_main_text, get_price_main_keyboard
                        await update.message.reply_text(
                            get_price_main_text(), parse_mode="Markdown",
                            reply_markup=get_price_main_keyboard()
                        )
                    elif action_type == "payment":
                        from src.payments import get_payment_keyboard
                        await update.message.reply_text(
                            "üí≥ –í—ã–±–µ—Ä–∏—Ç–µ —Å–ø–æ—Å–æ–± –æ–ø–ª–∞—Ç—ã:",
                            reply_markup=get_payment_keyboard()
                        )
            
            if agentic_result.get("text"):
                response_text = agentic_result["text"]
            elif special_actions and not agentic_result.get("text"):
                typing_task.cancel()
                session.add_message("assistant", "–ü–æ–∫–∞–∑–∞–ª –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é", config.max_history_length)
                lead_manager.save_message(user.id, "assistant", "–ü–æ–∫–∞–∑–∞–ª –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é")
                _run_voice_post_processing(user.id, transcription, session)
                return
        except Exception as e:
            logger.warning(f"Voice agentic loop failed, falling back to direct: {e}")
            
            from src.knowledge_base import SYSTEM_PROMPT
            from google import genai
            from google.genai import types
            
            client = genai.Client(api_key=config.gemini_api_key)
            
            history_text = ""
            for msg in session.get_history()[-6:]:
                role = "–ö–ª–∏–µ–Ω—Ç" if msg.get("role") == "user" else "–ê–ª–µ–∫—Å"
                parts = msg.get("parts", [])
                txt = parts[0].get("text", "") if parts else ""
                if txt and not txt.startswith("[–°–ò–°–¢–ï–ú–ù–´–ô"):
                    history_text += f"{role}: {txt}\n"
            
            context_addition = ""
            if client_context:
                context_addition = f"\n[–ö–û–ù–¢–ï–ö–°–¢]\n{client_context}\n"
            
            full_prompt = (
                f"{context_addition}"
                f"–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞:\n{history_text}\n"
                f"–ö–ª–∏–µ–Ω—Ç —Å–∫–∞–∑–∞–ª –≥–æ–ª–æ—Å–æ–≤—ã–º: {transcription}\n\n"
                f"–û—Ç–≤–µ—Ç—å –∫–∞–∫ –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ê–ª–µ–∫—Å."
            )
            
            response = await asyncio.to_thread(
                client.models.generate_content,
                model=config.model_name,
                contents=[full_prompt],
                config=types.GenerateContentConfig(
                    system_instruction=SYSTEM_PROMPT,
                    max_output_tokens=1500,
                    temperature=0.7
                )
            )
            
            if response.text:
                response_text = response.text
        
        if not response_text:
            response_text = "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å."
        
        session.add_message("assistant", response_text, config.max_history_length)
        lead_manager.save_message(user.id, "assistant", response_text)
        
        typing_task.cancel()
        try:
            await typing_task
        except asyncio.CancelledError:
            pass
        
        voice_sent = False
        if config.elevenlabs_api_key:
            try:
                await update.effective_chat.send_action(ChatAction.RECORD_VOICE)
                voice_response = await generate_voice_response(response_text)
                await update.message.reply_voice(voice=voice_response)
                voice_sent = True
            except Exception as e:
                logger.error(f"ElevenLabs TTS error ({type(e).__name__}): {e}")
        
        if not voice_sent:
            dynamic_btns = get_dynamic_buttons(user.id, transcription, session.message_count)
            reply_markup = None
            if dynamic_btns:
                keyboard_rows = [[InlineKeyboardButton(text, callback_data=cb)] for text, cb in dynamic_btns[:3]]
                reply_markup = InlineKeyboardMarkup(keyboard_rows)
            
            if len(response_text) > 4096:
                chunks = [response_text[i:i+4096] for i in range(0, len(response_text), 4096)]
                for i, chunk in enumerate(chunks):
                    if i == len(chunks) - 1:
                        await update.message.reply_text(chunk, reply_markup=reply_markup)
                    else:
                        await update.message.reply_text(chunk)
            else:
                await update.message.reply_text(response_text, reply_markup=reply_markup)
        else:
            dynamic_btns = get_dynamic_buttons(user.id, transcription, session.message_count)
            if dynamic_btns:
                keyboard_rows = [[InlineKeyboardButton(text, callback_data=cb)] for text, cb in dynamic_btns[:3]]
                reply_markup = InlineKeyboardMarkup(keyboard_rows)
                await update.message.reply_text(
                    "‚òùÔ∏è –û—Ç–≤–µ—Ç–∏–ª –≥–æ–ª–æ—Å–æ–≤—ã–º. –ï—Å–ª–∏ –Ω—É–∂–Ω—ã –¥–µ—Ç–∞–ª–∏:",
                    reply_markup=reply_markup
                )
        
        logger.info(f"User {user.id}: voice message processed (agentic, voice_reply={'yes' if voice_sent else 'no'})")
        
        _run_voice_post_processing(user.id, transcription, session)
        
    except Exception as e:
        typing_task.cancel()
        logger.error(f"Voice processing error: {e}")
        await update.message.reply_text(
            "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ. –ù–∞–ø–∏—à–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–º, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞."
        )


def _run_voice_post_processing(user_id: int, transcription: str, session):
    from src.handlers.messages import auto_tag_lead, auto_score_lead, extract_insights_if_needed, summarize_if_needed
    
    auto_tag_lead(user_id, transcription)
    auto_score_lead(user_id, transcription)
    
    asyncio.create_task(
        extract_insights_if_needed(user_id, session)
    )
    asyncio.create_task(
        summarize_if_needed(user_id, session)
    )


async def video_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user = update.effective_user
    user_id = user.id
    
    if context.user_data.get('broadcast_compose'):
        from src.security import is_admin
        if is_admin(user.id):
            context.user_data.pop('broadcast_compose', None)
            video = update.message.video or update.message.video_note
            context.user_data['broadcast_draft'] = {
                'type': 'video',
                'file_id': video.file_id,
                'caption': update.message.caption or '',
            }
            from src.broadcast import broadcast_manager
            counts = broadcast_manager.get_audience_counts()
            from src.handlers.utils import get_broadcast_audience_keyboard
            keyboard = get_broadcast_audience_keyboard(counts)
            caption_preview = f"\nüìù {update.message.caption}" if update.message.caption else ""
            await update.message.reply_text(
                f"üìã <b>–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä —Ä–∞—Å—Å—ã–ª–∫–∏:</b>\n\nüé¨ –í–∏–¥–µ–æ{caption_preview}\n\n<b>–í—ã–±–µ—Ä–∏—Ç–µ –∞—É–¥–∏—Ç–æ—Ä–∏—é:</b>",
                parse_mode="HTML",
                reply_markup=keyboard
            )
            return
    
    pending_review_type = context.user_data.get("pending_review_type")
    
    if pending_review_type != "video":
        await update.message.reply_text(
            "–ï—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ –æ—Å—Ç–∞–≤–∏—Ç—å –≤–∏–¥–µ–æ-–æ—Ç–∑—ã–≤, –Ω–∞–∂–º–∏—Ç–µ /bonus ‚Üí –û—Ç–∑—ã–≤—ã –∏ –±–æ–Ω—É—Å—ã ‚Üí –í–∏–¥–µ–æ-–æ—Ç–∑—ã–≤"
        )
        return
    
    video = update.message.video or update.message.video_note
    if not video:
        return
    
    file_id = video.file_id
    
    try:
        review = loyalty_system.submit_review(
            user_id=user_id,
            review_type="video",
            content=f"[VIDEO] file_id: {file_id}"
        )
        
        if review:
            context.user_data.pop("pending_review_type", None)
            
            from src.loyalty import REVIEW_REWARDS
            coins = REVIEW_REWARDS.get("video", 500)
            
            await update.message.reply_text(
                f"""‚úÖ <b>–í–∏–¥–µ–æ-–æ—Ç–∑—ã–≤ –ø—Ä–∏–Ω—è—Ç!</b>

–°–ø–∞—Å–∏–±–æ –∑–∞ –≤–∞—à –æ—Ç–∑—ã–≤! –ü–æ—Å–ª–µ –º–æ–¥–µ—Ä–∞—Ü–∏–∏ –≤—ã –ø–æ–ª—É—á–∏—Ç–µ <b>{coins} –º–æ–Ω–µ—Ç</b>.

–û–±—ã—á–Ω–æ –º–æ–¥–µ—Ä–∞—Ü–∏—è –∑–∞–Ω–∏–º–∞–µ—Ç –¥–æ 24 —á–∞—Å–æ–≤.""",
                parse_mode="HTML",
                reply_markup=get_loyalty_menu_keyboard()
            )
            
            if MANAGER_CHAT_ID:
                try:
                    manager_text = f"""üé¨ <b>–ù–æ–≤—ã–π –≤–∏–¥–µ–æ-–æ—Ç–∑—ã–≤!</b>

üë§ {user.first_name or '–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å'} (@{user.username or 'no_username'})
üÜî ID: {user_id}"""
                    
                    await context.bot.send_message(
                        chat_id=MANAGER_CHAT_ID,
                        text=manager_text,
                        parse_mode="HTML"
                    )
                    await context.bot.forward_message(
                        chat_id=MANAGER_CHAT_ID,
                        from_chat_id=update.effective_chat.id,
                        message_id=update.message.message_id
                    )
                except Exception as e:
                    logger.warning(f"Failed to notify manager about video review: {e}")
        else:
            await update.message.reply_text(
                "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç–∑—ã–≤. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
                reply_markup=get_loyalty_menu_keyboard()
            )
            context.user_data.pop("pending_review_type", None)
            
    except Exception as e:
        logger.error(f"Error processing video review: {e}")
        await update.message.reply_text(
            "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
            reply_markup=get_loyalty_menu_keyboard()
        )
        context.user_data.pop("pending_review_type", None)


async def photo_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user = update.effective_user
    user_id = user.id
    
    if context.user_data.get('broadcast_compose'):
        from src.security import is_admin
        if is_admin(user_id):
            context.user_data.pop('broadcast_compose', None)
            photo = update.message.photo[-1]
            context.user_data['broadcast_draft'] = {
                'type': 'photo',
                'file_id': photo.file_id,
                'caption': update.message.caption or '',
            }
            from src.broadcast import broadcast_manager
            counts = broadcast_manager.get_audience_counts()
            from src.handlers.utils import get_broadcast_audience_keyboard
            keyboard = get_broadcast_audience_keyboard(counts)
            caption_preview = f"\nüìù {update.message.caption}" if update.message.caption else ""
            await update.message.reply_text(
                f"üìã <b>–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä —Ä–∞—Å—Å—ã–ª–∫–∏:</b>\n\nüì∏ –§–æ—Ç–æ{caption_preview}\n\n<b>–í—ã–±–µ—Ä–∏—Ç–µ –∞—É–¥–∏—Ç–æ—Ä–∏—é:</b>",
                parse_mode="HTML",
                reply_markup=keyboard
            )
            return
    
    pending_review_type = context.user_data.get("pending_review_type")
    
    if pending_review_type != "text_photo":
        typing_task = asyncio.create_task(
            send_typing_action(update, duration=30.0)
        )
        try:
            photo = update.message.photo[-1] if update.message.photo else None
            if not photo:
                return
            
            file = await context.bot.get_file(photo.file_id)
            photo_bytes = await file.download_as_bytearray()
            
            from google import genai
            from google.genai import types
            from src.knowledge_base import SYSTEM_PROMPT
            
            client = genai.Client(api_key=config.gemini_api_key)
            
            caption = update.message.caption or ""
            
            image_part = types.Part.from_bytes(data=bytes(photo_bytes), mime_type="image/jpeg")
            
            user_instruction = caption if caption else "–ö–ª–∏–µ–Ω—Ç –æ—Ç–ø—Ä–∞–≤–∏–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —á—Ç–æ –Ω–∞ –Ω—ë–º –∏ –æ—Ç–≤–µ—Ç—å –∫–∞–∫ –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ê–ª–µ–∫—Å –∏–∑ WEB4TG Studio. –ï—Å–ª–∏ —ç—Ç–æ —Å–∫—Ä–∏–Ω—à–æ—Ç –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –∏–ª–∏ –¥–∏–∑–∞–π–Ω ‚Äî –æ—Ü–µ–Ω–∏ –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ —É–ª—É—á—à–µ–Ω–∏—è. –ï—Å–ª–∏ —ç—Ç–æ –¢–ó –∏–ª–∏ —Å—Ö–µ–º–∞ ‚Äî –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏ –¥–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏. –ï—Å–ª–∏ —ç—Ç–æ —á—Ç–æ-—Ç–æ –¥—Ä—É–≥–æ–µ ‚Äî –≤–µ–∂–ª–∏–≤–æ —Å–ø—Ä–æ—Å–∏ –∫–∞–∫ —ç—Ç–æ —Å–≤—è–∑–∞–Ω–æ —Å —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–æ–π Mini App."
            
            text_part = types.Part(text=user_instruction)
            
            session = session_manager.get_session(
                user_id=user.id,
                username=user.username,
                first_name=user.first_name
            )
            
            response = await asyncio.to_thread(
                client.models.generate_content,
                model=config.model_name,
                contents=[image_part, text_part],
                config=types.GenerateContentConfig(
                    system_instruction=SYSTEM_PROMPT,
                    max_output_tokens=1000,
                    temperature=0.7
                )
            )
            
            typing_task.cancel()
            
            if response.text:
                session.add_message("user", f"[–§–æ—Ç–æ]{f': {caption}' if caption else ''}", config.max_history_length)
                session.add_message("assistant", response.text, config.max_history_length)
                
                lead_manager.save_message(user.id, "user", f"[–§–æ—Ç–æ]{f': {caption}' if caption else ''}")
                lead_manager.save_message(user.id, "assistant", response.text)
                lead_manager.log_event("photo_analysis", user.id)
                lead_manager.update_activity(user.id)
                
                await update.message.reply_text(response.text, parse_mode="Markdown")
            else:
                await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –æ–ø–∏—Å–∞—Ç—å —Å–ª–æ–≤–∞–º–∏ —á—Ç–æ –≤–∞–º –Ω—É–∂–Ω–æ.")
        except Exception as e:
            typing_task.cancel()
            logger.error(f"Photo analysis error: {e}")
            await update.message.reply_text(
                "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–æ—Ç–æ. –û–ø–∏—à–∏—Ç–µ —Å–ª–æ–≤–∞–º–∏ —á—Ç–æ –≤–∞–º –Ω—É–∂–Ω–æ, —è –ø–æ–º–æ–≥—É!"
            )
        return
    
    photo = update.message.photo[-1] if update.message.photo else None
    if not photo:
        return
    
    file_id = photo.file_id
    caption = update.message.caption or ""
    
    try:
        review_id = loyalty_system.submit_review(
            user_id=user_id,
            review_type="text_photo",
            content_url=f"[PHOTO] file_id: {file_id}",
            comment=caption if caption else None
        )
        
        if review_id:
            context.user_data.pop("pending_review_type", None)
            
            from src.loyalty import REVIEW_REWARDS
            coins = REVIEW_REWARDS.get("text_photo", 200)
            
            await update.message.reply_text(
                f"""‚úÖ <b>–û—Ç–∑—ã–≤ —Å —Ñ–æ—Ç–æ –ø—Ä–∏–Ω—è—Ç!</b>

–°–ø–∞—Å–∏–±–æ –∑–∞ –≤–∞—à –æ—Ç–∑—ã–≤! –ü–æ—Å–ª–µ –º–æ–¥–µ—Ä–∞—Ü–∏–∏ –≤—ã –ø–æ–ª—É—á–∏—Ç–µ <b>{coins} –º–æ–Ω–µ—Ç</b>.

–û–±—ã—á–Ω–æ –º–æ–¥–µ—Ä–∞—Ü–∏—è –∑–∞–Ω–∏–º–∞–µ—Ç –¥–æ 24 —á–∞—Å–æ–≤.""",
                parse_mode="HTML",
                reply_markup=get_loyalty_menu_keyboard()
            )
            
            if MANAGER_CHAT_ID:
                try:
                    manager_text = f"""üì∏ <b>–ù–æ–≤—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–∑—ã–≤ —Å —Ñ–æ—Ç–æ!</b>

üë§ {user.first_name or '–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å'} (@{user.username or 'no_username'})
üÜî ID: {user_id}
üí¨ –¢–µ–∫—Å—Ç: {caption or '(–±–µ–∑ –ø–æ–¥–ø–∏—Å–∏)'}"""
                    
                    await context.bot.send_message(
                        chat_id=MANAGER_CHAT_ID,
                        text=manager_text,
                        parse_mode="HTML"
                    )
                    await context.bot.forward_message(
                        chat_id=MANAGER_CHAT_ID,
                        from_chat_id=update.effective_chat.id,
                        message_id=update.message.message_id
                    )
                except Exception as e:
                    logger.warning(f"Failed to notify manager about photo review: {e}")
        else:
            await update.message.reply_text(
                "‚ùå –í—ã —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª—è–ª–∏ –æ—Ç–∑—ã–≤ —ç—Ç–æ–≥–æ —Ç–∏–ø–∞ –∏–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞.",
                reply_markup=get_loyalty_menu_keyboard()
            )
            context.user_data.pop("pending_review_type", None)
            
    except Exception as e:
        logger.error(f"Error processing photo review: {e}")
        await update.message.reply_text(
            "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
            reply_markup=get_loyalty_menu_keyboard()
        )
        context.user_data.pop("pending_review_type", None)
