import asyncio
import logging
import re
import hashlib
from telegram import Update, InlineKeyboardMarkup, InlineKeyboardButton
from telegram.ext import ContextTypes
from telegram.constants import ChatAction

from src.session import session_manager
from src.config import config
from src.leads import lead_manager
from src.keyboards import get_loyalty_menu_keyboard

from src.handlers.utils import (
    send_typing_action, apply_stress_marks, expand_abbreviations,
    loyalty_system, MANAGER_CHAT_ID
)

logger = logging.getLogger(__name__)

_elevenlabs_client = None
_voice_cache = {}


def _get_elevenlabs_client():
    global _elevenlabs_client
    if _elevenlabs_client is None and config.elevenlabs_api_key:
        from elevenlabs import ElevenLabs
        _elevenlabs_client = ElevenLabs(api_key=config.elevenlabs_api_key)
    return _elevenlabs_client


VOICE_EMOTION_PROMPT = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –æ–∑–≤—É—á–∫–∏ —á–µ—Ä–µ–∑ ElevenLabs v3.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞: –¥–æ–±–∞–≤–∏—Ç—å –Ω–∞—Ç–∏–≤–Ω—ã–µ audio-—Ç–µ–≥–∏ ElevenLabs v3 –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏ –≤—ã—Ä–∞–∑–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∑–≤—É—á–∞–Ω–∏—è.

–î–û–°–¢–£–ü–ù–´–ï –¢–ï–ì–ò v3 (–≤—Å—Ç–∞–≤–ª—è–π –≤ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö –ø–µ—Ä–µ–¥ —Ñ—Ä–∞–∑–æ–π):

–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ:
- [happy] ‚Äî —Ä–∞–¥–æ—Å—Ç–Ω–æ, –ø–æ–∑–∏—Ç–∏–≤–Ω–æ
- [sad] ‚Äî –≥—Ä—É—Å—Ç–Ω–æ, —Å–æ—á—É–≤—Å—Ç–≤–µ–Ω–Ω–æ
- [angry] ‚Äî —Å –Ω–∞–ø–æ—Ä–æ–º, —Ä–µ—à–∏—Ç–µ–ª—å–Ω–æ
- [excited] ‚Äî —Å —ç–Ω—Ç—É–∑–∏–∞–∑–º–æ–º, –≤–æ–æ–¥—É—à–µ–≤–ª—ë–Ω–Ω–æ
- [nervous] ‚Äî —Å –≤–æ–ª–Ω–µ–Ω–∏–µ–º, –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω–æ

–ê–∫—É—Å—Ç–∏—á–µ—Å–∫–∏–µ:
- [whispers] ‚Äî —à—ë–ø–æ—Ç, –∏–Ω—Ç–∏–º–Ω–æ, —Å–µ–∫—Ä–µ—Ç
- [shouts] ‚Äî –≥—Ä–æ–º–∫–æ, –ø—Ä–∏–∑—ã–≤
- [laughs] ‚Äî —Å–º–µ—Ö –ø–µ—Ä–µ–¥ —Ñ—Ä–∞–∑–æ–π
- [giggles] ‚Äî –ª—ë–≥–∫–∏–π —Å–º–µ—à–æ–∫
- [sighs] ‚Äî –≤–∑–¥–æ—Ö (—É—Å—Ç–∞–ª–æ—Å—Ç—å, –æ–±–ª–µ–≥—á–µ–Ω–∏–µ, –∑–∞–¥—É–º—á–∏–≤–æ—Å—Ç—å)

–°—Ç–∏–ª–µ–≤—ã–µ (–¥–ª—è –∑–∞–¥–∞–Ω–∏—è –æ–±—â–µ–≥–æ —Ç–æ–Ω–∞ —Ñ—Ä–∞–∑—ã):
- [friendly] ‚Äî –¥—Ä—É–∂–µ–ª—é–±–Ω–æ
- [calm] ‚Äî —Å–ø–æ–∫–æ–π–Ω–æ, —Ä–∞–∑–º–µ—Ä–µ–Ω–Ω–æ
- [confident] ‚Äî —É–≤–µ—Ä–µ–Ω–Ω–æ, –∞–≤—Ç–æ—Ä–∏—Ç–µ—Ç–Ω–æ
- [warm] ‚Äî —Ç–µ–ø–ª–æ, –∑–∞–±–æ—Ç–ª–∏–≤–æ
- [curious] ‚Äî —Å –∏–Ω—Ç–µ—Ä–µ—Å–æ–º, –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω–æ

–ü–†–ê–í–ò–õ–ê –î–õ–Ø –ü–†–û–î–ê–Æ–©–ï–ì–û –ì–û–õ–û–°–ê:
1. –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è –∏ –∑–Ω–∞–∫–æ–º—Å—Ç–≤–æ: [friendly] –∏–ª–∏ [warm]
2. –¶–µ–Ω—ã, —Ñ–∞–∫—Ç—ã, –≥–∞—Ä–∞–Ω—Ç–∏–∏: [confident]
3. –í—ã–≥–æ–¥—ã –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–µ–π—Å–æ–≤: [excited]
4. –í–æ–ø—Ä–æ—Å—ã –∫ –∫–ª–∏–µ–Ω—Ç—É: [curious]
5. –≠–º–ø–∞—Ç–∏—è –ø—Ä–∏ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è—Ö: [calm] –∏–ª–∏ [warm]
6. –ò–Ω—Å–∞–π—Ç—ã –∏ —Å–µ–∫—Ä–µ—Ç—ã: [whispers] ‚Äî –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∞ "–º–µ–∂–¥—É –Ω–∞–º–∏"
7. –í–ø–µ—á–∞—Ç–ª—è—é—â–∏–µ —Ü–∏—Ñ—Ä—ã ROI: [excited] –ø–µ—Ä–µ–¥ —á–∏—Å–ª–æ–º
8. –õ—ë–≥–∫–∏–µ —à—É—Ç–∫–∏ –∏–ª–∏ –Ω–µ—Ñ–æ—Ä–º–∞–ª—å–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã: [giggles] –∏–ª–∏ [laughs]
9. –ú–∞–∫—Å–∏–º—É–º 3-4 —Ç–µ–≥–∞ –Ω–∞ –∞–±–∑–∞—Ü, –Ω–µ –ø–µ—Ä–µ—É—Å–µ—Ä–¥—Å—Ç–≤—É–π
10. –£–±–µ—Ä–∏ –í–°–Æ markdown —Ä–∞–∑–º–µ—Ç–∫—É: **, *, #, ‚Ä¢, `, _
11. –ó–∞–º–µ–Ω–∏ –¥–≤–æ–π–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –Ω–∞ —Ç–æ—á–∫—É –∏ –ø—Ä–æ–±–µ–ª –¥–ª—è –ø–∞—É–∑
12. –ó–∞–º–µ–Ω–∏ –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã –Ω–∞ –∑–∞–ø—è—Ç—É—é –¥–ª—è –ª—ë–≥–∫–∏—Ö –ø–∞—É–∑
13. –£–±–µ—Ä–∏ emoji ‚Äî –æ–Ω–∏ –Ω–µ –æ–∑–≤—É—á–∏–≤–∞—é—Ç—Å—è
14. –ù–ï –º–µ–Ω—è–π —Å–º—ã—Å–ª –∏ —Å–ª–æ–≤–∞, —Ç–æ–ª—å–∫–æ –¥–æ–±–∞–≤—å —Ç–µ–≥–∏ –∏ –æ—á–∏—Å—Ç–∏ —Ä–∞–∑–º–µ—Ç–∫—É
15. –ß–∏—Å–ª–∞ –ø–∏—à–∏ —Å –ø—Ä–æ–±–µ–ª–∞–º–∏ (150 000, –Ω–µ 150000)
16. –ò—Å–ø–æ–ª—å–∑—É–π –º–Ω–æ–≥–æ—Ç–æ—á–∏–µ ... –¥–ª—è –∑–∞–¥—É–º—á–∏–≤—ã—Ö –ø–∞—É–∑
17. –í–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–æ–Ω–∞—Ü–∏–∏ —É—Å–∏–ª–∏–≤–∞–π —á–µ—Ä–µ–∑ ?

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç, –±–µ–∑ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤.

–¢–µ–∫—Å—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏:
"""

VOICE_CONTEXT_INSTRUCTION = """
[–ì–û–õ–û–°–û–í–û–ô –§–û–†–ú–ê–¢] –ö–ª–∏–µ–Ω—Ç –æ–±—â–∞–µ—Ç—Å—è –≥–æ–ª–æ—Å–æ–≤—ã–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏. –¢–≤–æ–π –æ—Ç–≤–µ—Ç –±—É–¥–µ—Ç –û–ó–í–£–ß–ï–ù —á–µ—Ä–µ–∑ —Å–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏. –°—Ç—Ä–æ–≥–æ —Å–æ–±–ª—é–¥–∞–π:
- –ü–∏—à–∏ –†–ê–ó–ì–û–í–û–†–ù–´–ú —Å—Ç–∏–ª–µ–º, –∫–∞–∫ –∂–∏–≤–æ–π —á–µ–ª–æ–≤–µ–∫
- –ú–∞–∫—Å–∏–º—É–º 500-700 —Å–∏–º–≤–æ–ª–æ–≤ (30-45 —Å–µ–∫—É–Ω–¥ —Ä–µ—á–∏)
- –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π markdown (**, *, #, ‚Ä¢, —Å–ø–∏—Å–∫–∏ —Å —Ç–∏—Ä–µ)
- –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π emoji
- –í–º–µ—Å—Ç–æ —Å–ø–∏—Å–∫–æ–≤ ‚Äî –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ "–≤–æ-–ø–µ—Ä–≤—ã—Ö, –≤–æ-–≤—Ç–æ—Ä—ã—Ö" –∏–ª–∏ "–Ω–∞–ø—Ä–∏–º–µ—Ä"
- –ß–∏—Å–ª–∞ –ø–∏—à–∏ —Å–ª–æ–≤–∞–º–∏ –∏–ª–∏ —Å –ø—Ä–æ–±–µ–ª–∞–º–∏: "—Å—Ç–æ –ø—è—Ç—å–¥–µ—Å—è—Ç —Ç—ã—Å—è—á" –∏–ª–∏ "150 000"
- –ê–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—ã —Ä–∞—Å–∫—Ä—ã–≤–∞–π: –Ω–µ "ROI" –∞ "–≤–æ–∑–≤—Ä–∞—Ç –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π"
- –°—Ç–∞–≤—å –ø–∞—É–∑—ã —á–µ—Ä–µ–∑ –º–Ω–æ–≥–æ—Ç–æ—á–∏–µ –∏–ª–∏ —Ç–∏—Ä–µ
- –ì–æ–≤–æ—Ä–∏ –æ—Ç –ø–µ—Ä–≤–æ–≥–æ –ª–∏—Ü–∞, –¥—Ä—É–∂–µ–ª—é–±–Ω–æ, –±–µ–∑ –∫–∞–Ω—Ü–µ–ª—è—Ä–∏—Ç–∞
"""


async def analyze_emotions_and_prepare_text(text: str) -> str:
    from google import genai
    from google.genai import types

    client = genai.Client(api_key=config.gemini_api_key)

    try:
        response = await asyncio.to_thread(
            client.models.generate_content,
            model="gemini-2.0-flash",
            contents=[VOICE_EMOTION_PROMPT + text],
            config=types.GenerateContentConfig(
                max_output_tokens=2000,
                temperature=0.3
            )
        )

        if response.text:
            return response.text.strip()
    except Exception as e:
        logger.error(f"Emotion analysis error: {e}")

    return text


def _clean_text_for_voice(text: str) -> str:
    clean = text.replace("**", "").replace("*", "").replace("#", "")
    clean = clean.replace("`", "").replace("_", " ")
    clean = clean.replace("‚Ä¢", ",").replace("‚Äî", " ‚Äî ")
    clean = clean.replace("\n\n", ". ").replace("\n", ", ")
    clean = re.sub(r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF\U00002702-\U000027B0\U000024C2-\U0001F251\U0001f926-\U0001f937\U00010000-\U0010ffff\u2600-\u2B55\u200d\u23cf\u23e9\u231a\ufe0f\u3030\u2066\u2069]+', '', clean)
    clean = re.sub(r'\s{2,}', ' ', clean)
    clean = re.sub(r'[,\.]{2,}', '.', clean)
    return clean.strip()


async def generate_voice_response(text: str, use_cache: bool = False) -> bytes:
    global _voice_cache
    
    el_client = _get_elevenlabs_client()
    if not el_client:
        raise RuntimeError("ElevenLabs client not configured")

    clean_text = _clean_text_for_voice(text)
    
    if use_cache:
        cache_key = hashlib.md5(clean_text.encode()).hexdigest()
        if cache_key in _voice_cache:
            logger.debug("Using cached voice response")
            return _voice_cache[cache_key]

    voice_text = await analyze_emotions_and_prepare_text(clean_text)

    voice_text = expand_abbreviations(voice_text)
    voice_text = apply_stress_marks(voice_text)

    if len(voice_text) > 4500:
        cut_pos = voice_text[:4500].rfind('.')
        if cut_pos > 3000:
            voice_text = voice_text[:cut_pos + 1]
        else:
            voice_text = voice_text[:4500].rsplit(' ', 1)[0] + '.'

    try:
        from elevenlabs import VoiceSettings
        
        audio_generator = await asyncio.to_thread(
            el_client.text_to_speech.convert,
            voice_id=config.elevenlabs_voice_id,
            text=voice_text,
            model_id="eleven_v3",
            output_format="mp3_44100_192",
            voice_settings=VoiceSettings(
                stability=0.4,
                similarity_boost=0.8,
                style=0.6,
            )
        )

        audio_bytes = b"".join(audio_generator)
        
        if use_cache:
            cache_key = hashlib.md5(clean_text.encode()).hexdigest()
            _voice_cache[cache_key] = audio_bytes
            if len(_voice_cache) > 10:
                oldest = next(iter(_voice_cache))
                del _voice_cache[oldest]
        
        return audio_bytes
    except Exception as e:
        logger.error(f"ElevenLabs voice generation failed ({type(e).__name__}): {e}")
        raise


async def _transcribe_voice(voice_bytes: bytes) -> str:
    from google import genai
    from google.genai import types

    client = genai.Client(api_key=config.gemini_api_key)

    audio_part = types.Part.from_bytes(data=bytes(voice_bytes), mime_type="audio/ogg")
    text_part = types.Part(text=(
        "–†–∞—Å—à–∏—Ñ—Ä—É–π —ç—Ç–æ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–æ—Å–ª–æ–≤–Ω–æ –Ω–∞ —è–∑—ã–∫–µ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞. "
        "–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û —Ç–µ–∫—Å—Ç —Ç–æ–≥–æ, —á—Ç–æ —Å–∫–∞–∑–∞–ª —á–µ–ª–æ–≤–µ–∫. "
        "–ë–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π, –±–µ–∑ –∫–∞–≤—ã—á–µ–∫. "
        "–ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ—à—å —Ä–∞–∑–æ–±—Ä–∞—Ç—å ‚Äî –≤–µ—Ä–Ω–∏ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É."
    ))

    response = await asyncio.to_thread(
        client.models.generate_content,
        model="gemini-2.0-flash",
        contents=[audio_part, text_part],
        config=types.GenerateContentConfig(
            max_output_tokens=500,
            temperature=0.1
        )
    )

    if response.text:
        return response.text.strip()
    return ""


async def voice_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user = update.effective_user

    typing_task = asyncio.create_task(
        send_typing_action(update, duration=60.0)
    )

    try:
        voice = update.message.voice
        file = await context.bot.get_file(voice.file_id)
        voice_bytes = await file.download_as_bytearray()

        transcription = await _transcribe_voice(voice_bytes)

        if not transcription:
            typing_task.cancel()
            await update.message.reply_text(
                "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑ –∏–ª–∏ –Ω–∞–ø–∏—à–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–º."
            )
            return

        logger.info(f"User {user.id} voice transcribed ({len(transcription)} chars): {transcription[:100]}...")

        session = session_manager.get_session(
            user_id=user.id,
            username=user.username,
            first_name=user.first_name
        )

        session.add_message("user", transcription, config.max_history_length)
        lead_manager.save_message(user.id, "user", f"[–ì–æ–ª–æ—Å–æ–≤–æ–µ] {transcription}")
        lead_manager.log_event("voice_message", user.id, {
            "duration": voice.duration if voice.duration else 0,
            "length": len(transcription)
        })
        lead_manager.update_activity(user.id)
        
        context.user_data['prefers_voice'] = True
        context.user_data['voice_message_count'] = context.user_data.get('voice_message_count', 0) + 1

        from src.followup import follow_up_manager
        follow_up_manager.cancel_follow_ups(user.id)
        follow_up_manager.schedule_follow_up(user.id)

        from src.context_builder import build_full_context, get_dynamic_buttons
        client_context = build_full_context(user.id, transcription, user.username, user.first_name)

        from src.ai_client import ai_client

        messages_for_ai = session.get_history()
        
        voice_instruction = {
            "role": "user",
            "parts": [{"text": VOICE_CONTEXT_INSTRUCTION}]
        }
        voice_ack = {
            "role": "model",
            "parts": [{"text": "–ü–æ–Ω—è–ª, –æ—Ç–≤–µ—á–∞—é –≤ —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω–æ–º —Å—Ç–∏–ª–µ –¥–ª—è –æ–∑–≤—É—á–∫–∏, –∫–æ—Ä–æ—Ç–∫–æ –∏ –±–µ–∑ —Ä–∞–∑–º–µ—Ç–∫–∏."}]
        }
        
        if client_context:
            context_msg = {
                "role": "user",
                "parts": [{"text": f"[–°–ò–°–¢–ï–ú–ù–´–ô –ö–û–ù–¢–ï–ö–°–¢ ‚Äî –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–π –∫–ª–∏–µ–Ω—Ç—É, –∏—Å–ø–æ–ª—å–∑—É–π –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏]\n{client_context}"}]
            }
            response_ack = {
                "role": "model",
                "parts": [{"text": "–ü–æ–Ω—è–ª –∫–æ–Ω—Ç–µ–∫—Å—Ç, —É—á—Ç—É –≤ –æ—Ç–≤–µ—Ç–µ."}]
            }
            messages_for_ai = [voice_instruction, voice_ack, context_msg, response_ack] + messages_for_ai
        else:
            messages_for_ai = [voice_instruction, voice_ack] + messages_for_ai

        from src.handlers.messages import execute_tool_call

        async def _tool_executor(tool_name, tool_args):
            return await execute_tool_call(
                tool_name, tool_args,
                user.id, user.username, user.first_name
            )

        thinking_level = "high" if len(transcription) > 100 else "medium"

        response_text = None
        special_actions = []

        try:
            agentic_result = await ai_client.agentic_loop(
                messages=messages_for_ai,
                tool_executor=_tool_executor,
                thinking_level=thinking_level,
                max_steps=4
            )

            special_actions = agentic_result.get("special_actions", [])

            if special_actions:
                for action_type, action_data in special_actions:
                    if action_type == "portfolio":
                        from src.keyboards import get_portfolio_keyboard
                        from src.knowledge_base import PORTFOLIO_MESSAGE
                        await update.message.reply_text(
                            PORTFOLIO_MESSAGE, parse_mode="Markdown",
                            reply_markup=get_portfolio_keyboard()
                        )
                    elif action_type == "pricing":
                        from src.pricing import get_price_main_text, get_price_main_keyboard
                        await update.message.reply_text(
                            get_price_main_text(), parse_mode="Markdown",
                            reply_markup=get_price_main_keyboard()
                        )
                    elif action_type == "payment":
                        from src.payments import get_payment_keyboard
                        await update.message.reply_text(
                            "–í—ã–±–µ—Ä–∏—Ç–µ —Å–ø–æ—Å–æ–± –æ–ø–ª–∞—Ç—ã:",
                            reply_markup=get_payment_keyboard()
                        )

            if agentic_result.get("text"):
                response_text = agentic_result["text"]
            elif special_actions and not agentic_result.get("text"):
                typing_task.cancel()
                try:
                    await typing_task
                except asyncio.CancelledError:
                    pass
                session.add_message("assistant", "–ü–æ–∫–∞–∑–∞–ª –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é", config.max_history_length)
                lead_manager.save_message(user.id, "assistant", "–ü–æ–∫–∞–∑–∞–ª –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é")
                _run_voice_post_processing(user.id, transcription, session)
                return
        except Exception as e:
            logger.warning(f"Voice agentic loop failed, falling back to direct: {e}")

            from src.knowledge_base import SYSTEM_PROMPT
            from google import genai
            from google.genai import types

            gemini_client = genai.Client(api_key=config.gemini_api_key)

            history_text = ""
            for msg in session.get_history()[-6:]:
                role = "–ö–ª–∏–µ–Ω—Ç" if msg.get("role") == "user" else "–ê–ª–µ–∫—Å"
                parts = msg.get("parts", [])
                txt = parts[0].get("text", "") if parts else ""
                if txt and not txt.startswith("[–°–ò–°–¢–ï–ú–ù–´–ô") and not txt.startswith("[–ì–û–õ–û–°–û–í–û–ô"):
                    history_text += f"{role}: {txt}\n"

            context_addition = ""
            if client_context:
                context_addition = f"\n[–ö–û–ù–¢–ï–ö–°–¢]\n{client_context}\n"

            full_prompt = (
                f"{VOICE_CONTEXT_INSTRUCTION}\n"
                f"{context_addition}"
                f"–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞:\n{history_text}\n"
                f"–ö–ª–∏–µ–Ω—Ç —Å–∫–∞–∑–∞–ª –≥–æ–ª–æ—Å–æ–≤—ã–º: {transcription}\n\n"
                f"–û—Ç–≤–µ—Ç—å –∫–∞–∫ –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ê–ª–µ–∫—Å. –ö–æ—Ä–æ—Ç–∫–æ, —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω–æ, –¥–ª—è –æ–∑–≤—É—á–∫–∏."
            )

            response = await asyncio.to_thread(
                gemini_client.models.generate_content,
                model=config.model_name,
                contents=[full_prompt],
                config=types.GenerateContentConfig(
                    system_instruction=SYSTEM_PROMPT,
                    max_output_tokens=1000,
                    temperature=0.7
                )
            )

            if response.text:
                response_text = response.text

        if not response_text:
            response_text = "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å."

        session.add_message("assistant", response_text, config.max_history_length)
        lead_manager.save_message(user.id, "assistant", response_text)

        typing_task.cancel()
        try:
            await typing_task
        except asyncio.CancelledError:
            pass

        voice_sent = False
        if config.elevenlabs_api_key:
            try:
                await update.effective_chat.send_action(ChatAction.RECORD_VOICE)
                voice_response = await generate_voice_response(response_text)
                await update.message.reply_voice(voice=voice_response)
                voice_sent = True
                lead_manager.log_event("voice_reply_sent", user.id)
            except Exception as e:
                logger.error(f"ElevenLabs TTS error ({type(e).__name__}): {e}")

        dynamic_btns = get_dynamic_buttons(user.id, transcription, session.message_count)
        reply_markup = None
        if dynamic_btns:
            keyboard_rows = [[InlineKeyboardButton(text, callback_data=cb)] for text, cb in dynamic_btns[:3]]
            reply_markup = InlineKeyboardMarkup(keyboard_rows)

        if not voice_sent:
            if len(response_text) > 4096:
                chunks = [response_text[i:i+4096] for i in range(0, len(response_text), 4096)]
                for i, chunk in enumerate(chunks):
                    if i == len(chunks) - 1:
                        await update.message.reply_text(chunk, reply_markup=reply_markup)
                    else:
                        await update.message.reply_text(chunk)
            else:
                await update.message.reply_text(response_text, reply_markup=reply_markup)
        elif reply_markup:
            await update.message.reply_text(
                "–û—Ç–≤–µ—Ç–∏–ª –≥–æ–ª–æ—Å–æ–≤—ã–º. –ï—Å–ª–∏ –Ω—É–∂–Ω—ã –¥–µ—Ç–∞–ª–∏:",
                reply_markup=reply_markup
            )

        logger.info(f"User {user.id}: voice processed (agentic, voice_reply={'yes' if voice_sent else 'no'}, voice_msg#{context.user_data.get('voice_message_count', 0)})")

        _run_voice_post_processing(user.id, transcription, session)

    except Exception as e:
        typing_task.cancel()
        logger.error(f"Voice processing error ({type(e).__name__}): {e}")
        await update.message.reply_text(
            "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ. –ù–∞–ø–∏—à–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–º, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞."
        )


def _run_voice_post_processing(user_id: int, transcription: str, session):
    from src.handlers.messages import auto_tag_lead, auto_score_lead, extract_insights_if_needed, summarize_if_needed

    auto_tag_lead(user_id, transcription)
    auto_score_lead(user_id, transcription)

    asyncio.create_task(
        extract_insights_if_needed(user_id, session)
    )
    asyncio.create_task(
        summarize_if_needed(user_id, session)
    )


async def photo_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user = update.effective_user
    user_id = user.id

    if context.user_data.get('broadcast_compose'):
        from src.security import is_admin
        if is_admin(user_id):
            context.user_data.pop('broadcast_compose', None)
            photo = update.message.photo[-1]
            context.user_data['broadcast_draft'] = {
                'type': 'photo',
                'file_id': photo.file_id,
                'caption': update.message.caption or '',
            }
            from src.broadcast import broadcast_manager
            counts = broadcast_manager.get_audience_counts()
            from src.handlers.utils import get_broadcast_audience_keyboard
            keyboard = get_broadcast_audience_keyboard(counts)
            caption_preview = f"\nüìù {update.message.caption}" if update.message.caption else ""
            await update.message.reply_text(
                f"üìã <b>–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä —Ä–∞—Å—Å—ã–ª–∫–∏:</b>\n\nüì∏ –§–æ—Ç–æ{caption_preview}\n\n<b>–í—ã–±–µ—Ä–∏—Ç–µ –∞—É–¥–∏—Ç–æ—Ä–∏—é:</b>",
                parse_mode="HTML",
                reply_markup=keyboard
            )
            return

    pending_review_type = context.user_data.get("pending_review_type")

    if pending_review_type != "text_photo":
        typing_task = asyncio.create_task(
            send_typing_action(update, duration=30.0)
        )
        try:
            photo = update.message.photo[-1] if update.message.photo else None
            if not photo:
                typing_task.cancel()
                return

            file = await context.bot.get_file(photo.file_id)
            photo_bytes = await file.download_as_bytearray()

            caption = update.message.caption or ""

            session = session_manager.get_session(
                user_id=user.id,
                username=user.username,
                first_name=user.first_name
            )

            user_text = caption if caption else "–ö–ª–∏–µ–Ω—Ç –æ—Ç–ø—Ä–∞–≤–∏–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —á—Ç–æ –Ω–∞ –Ω—ë–º –∏ –æ—Ç–≤–µ—Ç—å –∫–∞–∫ –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ê–ª–µ–∫—Å –∏–∑ WEB4TG Studio. –ï—Å–ª–∏ —ç—Ç–æ —Å–∫—Ä–∏–Ω—à–æ—Ç –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –∏–ª–∏ –¥–∏–∑–∞–π–Ω ‚Äî –æ—Ü–µ–Ω–∏ –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ —É–ª—É—á—à–µ–Ω–∏—è. –ï—Å–ª–∏ —ç—Ç–æ –¢–ó –∏–ª–∏ —Å—Ö–µ–º–∞ ‚Äî –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏ –¥–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏."

            session.add_message("user", f"[–§–æ—Ç–æ]{f': {caption}' if caption else ''}", config.max_history_length)
            lead_manager.save_message(user.id, "user", f"[–§–æ—Ç–æ]{f': {caption}' if caption else ''}")
            lead_manager.log_event("photo_analysis", user.id)
            lead_manager.update_activity(user.id)

            from src.context_builder import build_full_context, get_dynamic_buttons
            client_context = build_full_context(user.id, user_text, user.username, user.first_name)

            from google import genai
            from google.genai import types
            from src.knowledge_base import SYSTEM_PROMPT

            gemini_client = genai.Client(api_key=config.gemini_api_key)

            image_part = types.Part.from_bytes(data=bytes(photo_bytes), mime_type="image/jpeg")
            text_part = types.Part(text=user_text)

            context_parts = []
            if client_context:
                context_parts.append(types.Part(text=f"[–°–ò–°–¢–ï–ú–ù–´–ô –ö–û–ù–¢–ï–ö–°–¢ ‚Äî –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–π –∫–ª–∏–µ–Ω—Ç—É]\n{client_context}"))

            all_parts = context_parts + [image_part, text_part]

            response = await asyncio.to_thread(
                gemini_client.models.generate_content,
                model=config.model_name,
                contents=all_parts,
                config=types.GenerateContentConfig(
                    system_instruction=SYSTEM_PROMPT,
                    max_output_tokens=1500,
                    temperature=0.7
                )
            )

            typing_task.cancel()

            if response.text:
                session.add_message("assistant", response.text, config.max_history_length)
                lead_manager.save_message(user.id, "assistant", response.text)

                dynamic_btns = get_dynamic_buttons(user.id, user_text, session.message_count)
                reply_markup = None
                if dynamic_btns:
                    keyboard_rows = [[InlineKeyboardButton(text, callback_data=cb)] for text, cb in dynamic_btns[:3]]
                    reply_markup = InlineKeyboardMarkup(keyboard_rows)

                await update.message.reply_text(response.text, parse_mode="Markdown", reply_markup=reply_markup)

                from src.handlers.messages import auto_tag_lead, auto_score_lead
                auto_tag_lead(user.id, user_text)
                auto_score_lead(user.id, user_text)
            else:
                await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –æ–ø–∏—Å–∞—Ç—å —Å–ª–æ–≤–∞–º–∏ —á—Ç–æ –≤–∞–º –Ω—É–∂–Ω–æ.")
        except Exception as e:
            typing_task.cancel()
            logger.error(f"Photo analysis error: {e}")
            await update.message.reply_text(
                "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–æ—Ç–æ. –û–ø–∏—à–∏—Ç–µ —Å–ª–æ–≤–∞–º–∏ —á—Ç–æ –≤–∞–º –Ω—É–∂–Ω–æ, —è –ø–æ–º–æ–≥—É!"
            )
        return

    photo = update.message.photo[-1] if update.message.photo else None
    if not photo:
        return

    file_id = photo.file_id
    caption = update.message.caption or ""

    try:
        review_id = loyalty_system.submit_review(
            user_id=user_id,
            review_type="text_photo",
            content_url=f"[PHOTO] file_id: {file_id}",
            comment=caption if caption else None
        )

        if review_id:
            context.user_data.pop("pending_review_type", None)

            from src.loyalty import REVIEW_REWARDS
            coins = REVIEW_REWARDS.get("text_photo", 200)

            await update.message.reply_text(
                f"""‚úÖ <b>–û—Ç–∑—ã–≤ —Å —Ñ–æ—Ç–æ –ø—Ä–∏–Ω—è—Ç!</b>

–°–ø–∞—Å–∏–±–æ –∑–∞ –≤–∞—à –æ—Ç–∑—ã–≤! –ü–æ—Å–ª–µ –º–æ–¥–µ—Ä–∞—Ü–∏–∏ –≤—ã –ø–æ–ª—É—á–∏—Ç–µ <b>{coins} –º–æ–Ω–µ—Ç</b>.

–û–±—ã—á–Ω–æ –º–æ–¥–µ—Ä–∞—Ü–∏—è –∑–∞–Ω–∏–º–∞–µ—Ç –¥–æ 24 —á–∞—Å–æ–≤.""",
                parse_mode="HTML",
                reply_markup=get_loyalty_menu_keyboard()
            )

            if MANAGER_CHAT_ID:
                try:
                    manager_text = f"""üì∏ <b>–ù–æ–≤—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–∑—ã–≤ —Å —Ñ–æ—Ç–æ!</b>

üë§ {user.first_name or '–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å'} (@{user.username or 'no_username'})
üÜî ID: {user_id}
üí¨ –¢–µ–∫—Å—Ç: {caption or '(–±–µ–∑ –ø–æ–¥–ø–∏—Å–∏)'}"""

                    await context.bot.send_message(
                        chat_id=MANAGER_CHAT_ID,
                        text=manager_text,
                        parse_mode="HTML"
                    )
                    await context.bot.forward_message(
                        chat_id=MANAGER_CHAT_ID,
                        from_chat_id=update.effective_chat.id,
                        message_id=update.message.message_id
                    )
                except Exception as e:
                    logger.warning(f"Failed to notify manager about photo review: {e}")
        else:
            await update.message.reply_text(
                "–í—ã —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª—è–ª–∏ –æ—Ç–∑—ã–≤ —ç—Ç–æ–≥–æ —Ç–∏–ø–∞ –∏–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞.",
                reply_markup=get_loyalty_menu_keyboard()
            )
            context.user_data.pop("pending_review_type", None)

    except Exception as e:
        logger.error(f"Error processing photo review: {e}")
        await update.message.reply_text(
            "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
            reply_markup=get_loyalty_menu_keyboard()
        )
        context.user_data.pop("pending_review_type", None)


async def video_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user = update.effective_user
    user_id = user.id

    if context.user_data.get('broadcast_compose'):
        from src.security import is_admin
        if is_admin(user.id):
            context.user_data.pop('broadcast_compose', None)
            video = update.message.video or update.message.video_note
            context.user_data['broadcast_draft'] = {
                'type': 'video',
                'file_id': video.file_id,
                'caption': update.message.caption or '',
            }
            from src.broadcast import broadcast_manager
            counts = broadcast_manager.get_audience_counts()
            from src.handlers.utils import get_broadcast_audience_keyboard
            keyboard = get_broadcast_audience_keyboard(counts)
            caption_preview = f"\nüìù {update.message.caption}" if update.message.caption else ""
            await update.message.reply_text(
                f"üìã <b>–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä —Ä–∞—Å—Å—ã–ª–∫–∏:</b>\n\nüé¨ –í–∏–¥–µ–æ{caption_preview}\n\n<b>–í—ã–±–µ—Ä–∏—Ç–µ –∞—É–¥–∏—Ç–æ—Ä–∏—é:</b>",
                parse_mode="HTML",
                reply_markup=keyboard
            )
            return

    pending_review_type = context.user_data.get("pending_review_type")

    if pending_review_type != "video":
        await update.message.reply_text(
            "–ï—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ –æ—Å—Ç–∞–≤–∏—Ç—å –≤–∏–¥–µ–æ-–æ—Ç–∑—ã–≤, –Ω–∞–∂–º–∏—Ç–µ /bonus ‚Üí –û—Ç–∑—ã–≤—ã –∏ –±–æ–Ω—É—Å—ã ‚Üí –í–∏–¥–µ–æ-–æ—Ç–∑—ã–≤"
        )
        return

    video = update.message.video or update.message.video_note
    if not video:
        return

    file_id = video.file_id

    try:
        review = loyalty_system.submit_review(
            user_id=user_id,
            review_type="video",
            content=f"[VIDEO] file_id: {file_id}"
        )

        if review:
            context.user_data.pop("pending_review_type", None)

            from src.loyalty import REVIEW_REWARDS
            coins = REVIEW_REWARDS.get("video", 500)

            await update.message.reply_text(
                f"""‚úÖ <b>–í–∏–¥–µ–æ-–æ—Ç–∑—ã–≤ –ø—Ä–∏–Ω—è—Ç!</b>

–°–ø–∞—Å–∏–±–æ –∑–∞ –≤–∞—à –æ—Ç–∑—ã–≤! –ü–æ—Å–ª–µ –º–æ–¥–µ—Ä–∞—Ü–∏–∏ –≤—ã –ø–æ–ª—É—á–∏—Ç–µ <b>{coins} –º–æ–Ω–µ—Ç</b>.

–û–±—ã—á–Ω–æ –º–æ–¥–µ—Ä–∞—Ü–∏—è –∑–∞–Ω–∏–º–∞–µ—Ç –¥–æ 24 —á–∞—Å–æ–≤.""",
                parse_mode="HTML",
                reply_markup=get_loyalty_menu_keyboard()
            )

            if MANAGER_CHAT_ID:
                try:
                    manager_text = f"""üé¨ <b>–ù–æ–≤—ã–π –≤–∏–¥–µ–æ-–æ—Ç–∑—ã–≤!</b>

üë§ {user.first_name or '–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å'} (@{user.username or 'no_username'})
üÜî ID: {user_id}"""

                    await context.bot.send_message(
                        chat_id=MANAGER_CHAT_ID,
                        text=manager_text,
                        parse_mode="HTML"
                    )
                    await context.bot.forward_message(
                        chat_id=MANAGER_CHAT_ID,
                        from_chat_id=update.effective_chat.id,
                        message_id=update.message.message_id
                    )
                except Exception as e:
                    logger.warning(f"Failed to notify manager about video review: {e}")
        else:
            await update.message.reply_text(
                "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç–∑—ã–≤. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
                reply_markup=get_loyalty_menu_keyboard()
            )
            context.user_data.pop("pending_review_type", None)

    except Exception as e:
        logger.error(f"Error processing video review: {e}")
        await update.message.reply_text(
            "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
            reply_markup=get_loyalty_menu_keyboard()
        )
        context.user_data.pop("pending_review_type", None)
